[
  {
    "objectID": "slides/04-group-by.html#last-week",
    "href": "slides/04-group-by.html#last-week",
    "title": "Multivariate Summaries",
    "section": "Last Week",
    "text": "Last Week\n\nReading in data and cleaning / prepping it.\nSummarizing one categorical variable with a distribution.\nSummarizing two categorical variables with joint and conditional distributions.\nUsing plotnine and the grammar of graphics to make bar plots and column plots.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#quantitative-variables-so-far",
    "href": "slides/04-group-by.html#quantitative-variables-so-far",
    "title": "Multivariate Summaries",
    "section": "Quantitative Variables So Far",
    "text": "Quantitative Variables So Far\n\nVisualizing by converting to categorical.\nVisualizing with histograms or densities.\nEstimating probabilities from histograms and densities.\nDescribing the skew.\nCalculating and explaining the mean and the median.\nCalculating and explaining the standard deviation and variance.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#new-dataset-airplane-flights",
    "href": "slides/04-group-by.html#new-dataset-airplane-flights",
    "title": "Multivariate Summaries",
    "section": "New dataset: Airplane Flights",
    "text": "New dataset: Airplane Flights\n\nWhich airline carriers are most likely to be delayed?\n\n\nLet’s look at a data set of all domestic flights that departed from one of New York City’s airports (JFK, LaGuardia, and Newark) on November 16, 2013.\n\n\ndata_dir = \"https://datasci112.stanford.edu/data/\"\ndf = pd.read_csv(data_dir + \"flights_nyc_20131116.csv\")\ndf\n\n    carrier  flight origin dest  dep_delay\n0        US    1895    EWR  CLT       -5.0\n1        UA    1014    LGA  IAH       -3.0\n2        AA    2243    JFK  MIA        2.0\n3        UA     303    JFK  SFO       -8.0\n4        US     795    LGA  PHL       -8.0\n..      ...     ...    ...  ...        ...\n573      B6     745    JFK  PSE       -3.0\n574      B6     839    JFK  BQN        0.0\n575      UA     360    EWR  PBI        NaN\n576      US    1946    EWR  CLT        NaN\n577      US    2142    LGA  BOS        NaN\n\n[578 rows x 5 columns]",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays",
    "href": "slides/04-group-by.html#delays",
    "title": "Multivariate Summaries",
    "section": "Delays",
    "text": "Delays\nWe already know how to summarize the flight delays:\n\n\n\n\n\n\nCheck-in 2.2: Interpret these numbers!\n\n\n\n\n\n\n\ndf['dep_delay'].median()\n\nnp.float64(-4.0)\n\ndf['dep_delay'].mean()\n\nnp.float64(2.0469565217391303)\n\ndf['dep_delay'].std()\n\nnp.float64(23.52882923523891)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-1",
    "href": "slides/04-group-by.html#delays-1",
    "title": "Multivariate Summaries",
    "section": "Delays",
    "text": "Delays\nWe already know how to visualize the flight delays:\n\n\n\n\n\n\nCheck-in 2.2: How would you describe this distribution?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-by-origin",
    "href": "slides/04-group-by.html#delays-by-origin",
    "title": "Multivariate Summaries",
    "section": "Delays by Origin",
    "text": "Delays by Origin\n\nDo the three origin airports (JFK, LGA, EWR) have different delay patterns?\n\n\n\n\n\n\n\n\nCheck-in 2.2: What could you change in this code to include the origin variable?\n\n\n\n\n\n\n\n(\n  ggplot(df, aes(x = 'dep_delay')) + \n  geom_histogram() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-by-origin-1",
    "href": "slides/04-group-by.html#delays-by-origin-1",
    "title": "Multivariate Summaries",
    "section": "Delays by Origin",
    "text": "Delays by Origin\nOverlapping histograms can be really hard to read…\n\n\n\nCode\n(\n  ggplot(df, aes(x = 'dep_delay', fill = 'origin')) + \n  geom_histogram() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-by-origin-2",
    "href": "slides/04-group-by.html#delays-by-origin-2",
    "title": "Multivariate Summaries",
    "section": "Delays by Origin",
    "text": "Delays by Origin\n… but overlapping densities often look nicer…\n\n\n\nCode\n(\n  ggplot(df, aes(x = 'dep_delay', fill = 'origin')) + \n  geom_density() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-by-origin-3",
    "href": "slides/04-group-by.html#delays-by-origin-3",
    "title": "Multivariate Summaries",
    "section": "Delays by Origin",
    "text": "Delays by Origin\n… especially if we make them a little see-through!\n\n\n\nCode\n(\n  ggplot(df, aes(x = 'dep_delay', fill = 'origin')) + \n  geom_density(alpha = 0.5) + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#variable-transformations",
    "href": "slides/04-group-by.html#variable-transformations",
    "title": "Multivariate Summaries",
    "section": "Variable Transformations",
    "text": "Variable Transformations\n\nThat last plot was okay, but it was hard to see the details, because the distribution is so skewed right.\nSometimes, for easier visualization, it is worth transforming a variable.\nFor skewed data, we often use a log transformation.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#log-transformation",
    "href": "slides/04-group-by.html#log-transformation",
    "title": "Multivariate Summaries",
    "section": "Log Transformation",
    "text": "Log Transformation\nExample: Salaries of $10,000, and $100,000, and $10,000,000:\n\n\ndat = pd.DataFrame({\"salary\": [10000, 100000, 10000000]})\ndat[\"log_salary\"] = np.log(dat[\"salary\"])\n\n\n\n\n\n\n\nCode\n(\n  ggplot(data = dat, mapping = aes(x = \"salary\")) + \n  geom_histogram(bins = 100) + \n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n(\n  ggplot(data = dat, mapping = aes(x = \"log_salary\")) + \n  geom_histogram(bins = 100) + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#log-transformations",
    "href": "slides/04-group-by.html#log-transformations",
    "title": "Multivariate Summaries",
    "section": "Log transformations",
    "text": "Log transformations\n\nUsually, we use the natural log, just for convenience.\n\n\n\nPros:\nSkewed data looks less skewed, so it is easier to see patterns.\n\n\n\nCons:\nThe variable is now on a different scale so it is not as interpretable.\n\n\n\n\n\n\n\n\nRemember, log transformations need positive numbers!",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#delays-by-origin---transformed",
    "href": "slides/04-group-by.html#delays-by-origin---transformed",
    "title": "Multivariate Summaries",
    "section": "Delays by Origin - Transformed",
    "text": "Delays by Origin - Transformed\n\n\n\nCode\n# Shift delays to be above zero\ndf['delay_shifted'] = df['dep_delay'] - df['dep_delay'].min() + 1\n\n# Log transform\ndf['log_delay'] = np.log(df['delay_shifted'])\n\n(\n  ggplot(df, aes(x = 'log_delay', fill = 'origin')) + \n  geom_density(alpha = 0.5) + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#another-option-boxplots",
    "href": "slides/04-group-by.html#another-option-boxplots",
    "title": "Multivariate Summaries",
    "section": "Another option: Boxplots",
    "text": "Another option: Boxplots\n\n\n\n\n\nCode\n(\n  ggplot(df, mapping = aes(y = 'log_delay', x = 'origin')) + \n  geom_boxplot() + \n  labs(x = \"\", \n       y = \"Log Delay (minutes)\", \n       title = \"Comparing Departure Delays for NYC Airports\") +\n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n(\n  ggplot(df, mapping = aes(y = 'log_delay', x = 'origin')) + \n  geom_boxplot() +\n  labs(x = \"\", \n       y = \"Log Delay (minutes)\", \n       title = \"Comparing Departure Delays for NYC Airports\") +\n  coord_flip() +\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#facetting-1",
    "href": "slides/04-group-by.html#facetting-1",
    "title": "Multivariate Summaries",
    "section": "Facetting",
    "text": "Facetting\n\nThis plot still was a little hard to read.\nWhat if we just made separate plots for each origin?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#separate-plots-for-each-origin",
    "href": "slides/04-group-by.html#separate-plots-for-each-origin",
    "title": "Multivariate Summaries",
    "section": "Separate Plots for Each Origin",
    "text": "Separate Plots for Each Origin\nOne option would be to create separate data frames for each origin.\n\n\nis_jfk = (df['origin'] == \"JFK\")\ndf_jfk = df[is_jfk]\ndf_jfk\n\n    carrier  flight origin dest  dep_delay  delay_shifted  log_delay\n2        AA    2243    JFK  MIA        2.0           22.0   3.091042\n3        UA     303    JFK  SFO       -8.0           12.0   2.484907\n11       EV    5716    JFK  IAD       -4.0           16.0   2.772589\n12       B6     583    JFK  MCO       -3.0           17.0   2.833213\n14       B6    1403    JFK  SJU       -2.0           18.0   2.890372\n..      ...     ...    ...  ...        ...            ...        ...\n570      B6     718    JFK  BOS        1.0           21.0   3.044522\n571      B6    1816    JFK  SYR       20.0           40.0   3.688879\n572      B6    1503    JFK  SJU      -10.0           10.0   2.302585\n573      B6     745    JFK  PSE       -3.0           17.0   2.833213\n574      B6     839    JFK  BQN        0.0           20.0   2.995732\n\n[208 rows x 7 columns]\n\n\n\n\nThis seems kind of annoying…",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#fyi-boolean-masking",
    "href": "slides/04-group-by.html#fyi-boolean-masking",
    "title": "Multivariate Summaries",
    "section": "FYI: Boolean Masking",
    "text": "FYI: Boolean Masking\nHow did we filter the previous df to only include \"JFK\" origins?\n\n\n\nStep 1\n\n\nis_jfk = (df['origin'] == \"JFK\")\nis_jfk\n\n0      False\n1      False\n2       True\n3       True\n4      False\n       ...  \n573     True\n574     True\n575    False\n576    False\n577    False\nName: origin, Length: 578, dtype: bool\n\n\n\n\n\n\n\n\nStep 2\n\n\ndf_jfk = df[is_jfk]\ndf_jfk[\"origin\"]\n\n2      JFK\n3      JFK\n11     JFK\n12     JFK\n14     JFK\n      ... \n570    JFK\n571    JFK\n572    JFK\n573    JFK\n574    JFK\nName: origin, Length: 208, dtype: object",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#facetting-2",
    "href": "slides/04-group-by.html#facetting-2",
    "title": "Multivariate Summaries",
    "section": "Facetting",
    "text": "Facetting\nFortunately, plotnine (and other plotting packages) has a trick for you!\n\n\n(\n  ggplot(df, aes(x = 'dep_delay')) + \n  geom_density() + \n  facet_wrap('origin')\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#freeing-the-scales",
    "href": "slides/04-group-by.html#freeing-the-scales",
    "title": "Multivariate Summaries",
    "section": "Freeing the Scales",
    "text": "Freeing the Scales\n\n\nCode\n(\n  ggplot(df, aes(x = 'dep_delay')) + \n  geom_density() + \n  facet_wrap('origin', scales = \"free_y\") +\n  labs(x = \"Departure Delay (minutes)\")\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#split-apply-combine",
    "href": "slides/04-group-by.html#split-apply-combine",
    "title": "Multivariate Summaries",
    "section": "Split-apply-combine",
    "text": "Split-apply-combine\n\n\n\nOur visualizations told us some of the story, but can we use numeric summaries as well?\nTo do this, we want to calculate the mean or median delay time for each origin airport.\nWe call this split-apply-combine:\n\nsplit the dataset up by a categorical variable origin\napply a calculation like mean\ncombine the results back into one dataset\n\nIn pandas, we use the groupby() function to take care of the split and combine steps!",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#group-by",
    "href": "slides/04-group-by.html#group-by",
    "title": "Multivariate Summaries",
    "section": "Group-by",
    "text": "Group-by\n\n\n\n\n(\n  df\n  .groupby(by = \"origin\")[\"dep_delay\"]\n  .mean()\n)\n\norigin\nEWR    4.064935\nJFK    1.461538\nLGA   -0.485294\nName: dep_delay, dtype: float64\n\n\n\n\n\n\n\n\n(\n  df\n  .groupby(by = \"origin\")[\"dep_delay\"]\n  .median()\n)\n\norigin\nEWR   -3.0\nJFK   -4.0\nLGA   -6.0\nName: dep_delay, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#group-by-check-in",
    "href": "slides/04-group-by.html#group-by-check-in",
    "title": "Multivariate Summaries",
    "section": "Group-by Check-in",
    "text": "Group-by Check-in\n\n\n\n\n\n\nCheck-in 2.2\n\n\n\nWhich code is causing “split by origin”?\nWhich code is causing “calculate the mean of delays”?\nWhich code is causing the re-combining of the data?\n\n\n\n\n\n(\n  df\n  .groupby(by = \"origin\")[\"dep_delay\"]\n  .mean()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#simple-example-exam-scores",
    "href": "slides/04-group-by.html#simple-example-exam-scores",
    "title": "Multivariate Summaries",
    "section": "Simple Example: Exam Scores",
    "text": "Simple Example: Exam Scores\nHermione’s exam scores are is:\n\nPotions class: 77/100\nCharms class: 95/100\nHerbology class: 90/100\n\nIn which class did she do best?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#but-wait",
    "href": "slides/04-group-by.html#but-wait",
    "title": "Multivariate Summaries",
    "section": "But wait!",
    "text": "But wait!\nThe class means are:\n\nPotions class: 75/100\nCharms class: 85/100\nHerbology class: 85/100\n\nIn which class did she do best?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#but-wait-1",
    "href": "slides/04-group-by.html#but-wait-1",
    "title": "Multivariate Summaries",
    "section": "But wait!",
    "text": "But wait!\nThe class standard deviations are:\n\nPotions class: 2 points\nCharms class: 5 points\nHerbology class: 1 point\n\nIn which class did she do best?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#different-variabilities-by-origin",
    "href": "slides/04-group-by.html#different-variabilities-by-origin",
    "title": "Multivariate Summaries",
    "section": "Different variabilities by origin",
    "text": "Different variabilities by origin\n\nIn addition to having different centers, the three origins also have different spreads.\n\n(\n  df\n  .groupby(\"origin\")[\"dep_delay\"]\n  .std()\n)\n\norigin\nEWR    25.646258\nJFK    18.713927\nLGA    26.121365\nName: dep_delay, dtype: float64\n\n\n\n\n\n\nIn general flights from \"LGA\" have departure delays that are the furthest from the mean.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#standardized-values-1",
    "href": "slides/04-group-by.html#standardized-values-1",
    "title": "Multivariate Summaries",
    "section": "Standardized values",
    "text": "Standardized values\n\nWe standardize values by subtracting the mean and dividing by the standard deviation.\nThis tells us how much better/worse than typical values our target value is.\nThis is also called the z-score. \\[z_i = \\frac{x_i - \\bar{x}}{s_x}\\]",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#standardized-values-2",
    "href": "slides/04-group-by.html#standardized-values-2",
    "title": "Multivariate Summaries",
    "section": "Standardized values",
    "text": "Standardized values\n\nSuppose you fly from LGA and your flight is 40 minutes late. Your friend flies from JFK and their flight is 30 minutes late.\nWho got “unluckier”?\n\n\n\n\nYou?\n\n(40 - -0.48) / 26.12\n\n1.5497702909647777\n\n\n\n\n\nYour friend?\n\n(30 - 1.46) / 18.71\n\n1.5253874933190805",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#activity-2.2",
    "href": "slides/04-group-by.html#activity-2.2",
    "title": "Multivariate Summaries",
    "section": "Activity 2.2",
    "text": "Activity 2.2\n\nWhat airlines have the most delays?\n\n\nMake a plot to answer the question.\nCalculate values to answer the question.\nThe first row is a flight from EWR to CLT on US Airways. The second row is a flight from LGA to IAH on United Airlines. Which one was a “more extreme” delay?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#did-older-passengers-pay-a-higher-fare-on-the-titanic",
    "href": "slides/04-group-by.html#did-older-passengers-pay-a-higher-fare-on-the-titanic",
    "title": "Multivariate Summaries",
    "section": "Did older passengers pay a higher fare on the Titanic?",
    "text": "Did older passengers pay a higher fare on the Titanic?\n\nTo visualize two quantitative variables, we make a scatterplot (or point geometry).\n\n\n\n\n\nCode\n(\n  ggplot(data = df_titanic, mapping = aes(x = 'age', y = 'fare')) + \n  geom_point() +\n  labs(x = \"Age of Passenger\", \n       y = \"Fare Paid on Titanic\")\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#scatterplots",
    "href": "slides/04-group-by.html#scatterplots",
    "title": "Multivariate Summaries",
    "section": "Scatterplots",
    "text": "Scatterplots\n\n\n\n\n\n\n\nNotice\n\n\n\nThe explanatory variable was on the x-axis.\nThe response variable was on the y-axis.\n“If you are older, you pay more” not “If you pay more, you get older”.\n\n\n\n\n\n(\n  ggplot(data = df_titanic, \n         mapping = aes(x = 'age', y = 'fare')\n         ) + \n  geom_point() +\n  labs(x = \"Age of Passenger\", \n       y = \"Fare Paid on Titanic\")\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#making-a-clearer-plot",
    "href": "slides/04-group-by.html#making-a-clearer-plot",
    "title": "Multivariate Summaries",
    "section": "Making a Clearer Plot",
    "text": "Making a Clearer Plot\nDid you notice how difficult it was to pick out each point?\n\n\n\nJittering\n\n\n\nCode\n(\n  ggplot(data = df_titanic, \n         mapping = aes(x = 'age', y = 'fare')\n         ) + \n  geom_jitter() +\n  labs(x = \"Age of Passenger\", \n       y = \"Fare Paid on Titanic\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTransparency\n\n\n\nCode\n(\n  ggplot(data = df_titanic, \n         mapping = aes(x = 'age', y = 'fare')\n         ) + \n  geom_point(alpha = 0.5) +\n  labs(x = \"Age of Passenger\", \n       y = \"Fare Paid on Titanic\")\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#spicing-things-up",
    "href": "slides/04-group-by.html#spicing-things-up",
    "title": "Multivariate Summaries",
    "section": "Spicing Things Up",
    "text": "Spicing Things Up\nHow could we make this more interesting?\n\nUse a log-transformation for fare because it is very skewed.\nAdd in a third variable, pclass. How might you do this?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#challenge",
    "href": "slides/04-group-by.html#challenge",
    "title": "Multivariate Summaries",
    "section": "Challenge",
    "text": "Challenge\nCan you re-create this plot?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#describing-a-scatterplot",
    "href": "slides/04-group-by.html#describing-a-scatterplot",
    "title": "Multivariate Summaries",
    "section": "Describing a Scatterplot",
    "text": "Describing a Scatterplot\nLet’s look at just third class:\n\n\n\nCode\nis_third= df_titanic['pclass'] == 3\ndf_third = df_titanic[is_third]\n\n(\n  ggplot(df_third, aes(x = 'age', y = 'fare')) + \n  geom_jitter(alpha = 0.8) + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#describing-the-relationship",
    "href": "slides/04-group-by.html#describing-the-relationship",
    "title": "Multivariate Summaries",
    "section": "Describing the Relationship",
    "text": "Describing the Relationship\n\n\nStrength\nNot very strong: the points don’t follow a clear pattern.\n\n\n\n\nDirection\nSlightly negative: When age was higher, fare was a little lower.\n\n\n\n\n\nShape\nNot very linear: the points don’t form a straight line.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#correlation",
    "href": "slides/04-group-by.html#correlation",
    "title": "Multivariate Summaries",
    "section": "Correlation",
    "text": "Correlation\nWhat if we want a numerical summary of the relationship between variables?\n\nDo “older than average” people pay “higher than average” fares?\n\nIn other words, when the z-score of age was high, was the z-score of fare also high?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#age-fare-correlation",
    "href": "slides/04-group-by.html#age-fare-correlation",
    "title": "Multivariate Summaries",
    "section": "Age & Fare Correlation",
    "text": "Age & Fare Correlation\n\n\n\nCode\nmean_age = df_third['age'].mean()\nmean_fare = df_third['fare'].mean()\n\n(\n  ggplot(data = df_third, mapping = aes(x = 'age', y = 'fare')) + \n  geom_jitter(alpha = 0.8) + \n  geom_vline(xintercept = mean_age, color = \"red\", linetype = \"dashed\") + \n  geom_hline(yintercept = mean_fare, color = \"red\", linetype = \"dashed\") + \n  labs(x = \"Age of Passenger\", \n       y = \"Titanic Fare Paid\")\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#correlation-1",
    "href": "slides/04-group-by.html#correlation-1",
    "title": "Multivariate Summaries",
    "section": "Correlation",
    "text": "Correlation\nInterpret this result:\n\ndf_third[['age', 'fare']].corr()\n\n           age      fare\nage   1.000000 -0.238137\nfare -0.238137  1.000000\n\n\n\n\nAge and fare are slightly negatively correlated.\nCan you think of an explanation for this?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#correlation-is-not-the-relationship",
    "href": "slides/04-group-by.html#correlation-is-not-the-relationship",
    "title": "Multivariate Summaries",
    "section": "Correlation is not the Relationship",
    "text": "Correlation is not the Relationship\n\nJust for fun: Guess the Correlation Game",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/04-group-by.html#takeaways-1",
    "href": "slides/04-group-by.html#takeaways-1",
    "title": "Multivariate Summaries",
    "section": "Takeaways",
    "text": "Takeaways\n\n\nPlot quantitative variables across groups with overlapping density plots, boxplots, or by facetting.\nSummarize quantitative variables across groups by using groupby() and then calculating summary statistics.\nKnow what split-apply-combine means.\nPlot relationships between quantitative variables with a scatterplot.\nDescribe the strength, direction, and shape of the relationship displayed in a scatterplot.\nSummarize relationships between quantitative variables with the correlation",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 2 - Multivariate Summaries"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#getting-prepping-and-summarizing-data",
    "href": "slides/03-quantitative-variables.html#getting-prepping-and-summarizing-data",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Getting, prepping, and summarizing data",
    "text": "Getting, prepping, and summarizing data\n\ndf = pd.read_csv(\"https://datasci112.stanford.edu/data/titanic.csv\")\n\ndf[\"pclass\"] = df[\"pclass\"].astype(\"category\")\ndf[\"survived\"] = df[\"survived\"].astype(\"category\")",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#marginal-distributions",
    "href": "slides/03-quantitative-variables.html#marginal-distributions",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Marginal Distributions",
    "text": "Marginal Distributions\nIf I choose a passenger at random, what is the probability they rode in 1st class?\n\nmarginal_class = (\n  df['pclass']\n  .value_counts(normalize = True)\n  )\nmarginal_class\n\npclass\n3    0.541635\n1    0.246753\n2    0.211612\nName: proportion, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#joint-distributions",
    "href": "slides/03-quantitative-variables.html#joint-distributions",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Joint Distributions",
    "text": "Joint Distributions\nIf I choose a passenger at random, what is the probability they are a woman who rode in first class?\n\njoint_class_sex = (\n  df[[\"pclass\", \"sex\"]]\n  .value_counts(normalize=True)\n  .unstack()\n  )\n  \njoint_class_sex\n\nsex       female      male\npclass                    \n1       0.110008  0.136746\n2       0.080978  0.130634\n3       0.165011  0.376623",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#conditional-distributions",
    "href": "slides/03-quantitative-variables.html#conditional-distributions",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Conditional Distributions",
    "text": "Conditional Distributions\nIf I choose a woman at random, what is the probability they rode in first class?\n\nmarginal_sex = (\n  df['sex']\n  .value_counts(normalize = True)\n  )\n  \njoint_class_sex.divide(marginal_sex)\n\nsex       female      male\npclass                    \n1       0.309013  0.212337\n2       0.227468  0.202847\n3       0.463519  0.584816",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#visualizing-with-plotnine",
    "href": "slides/03-quantitative-variables.html#visualizing-with-plotnine",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Visualizing with plotnine",
    "text": "Visualizing with plotnine\n\n\n(\n  ggplot(df, aes(x = \"sex\", fill = \"pclass\")) + \n  geom_bar(position = \"fill\") + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#quantitative-variables-1",
    "href": "slides/03-quantitative-variables.html#quantitative-variables-1",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Quantitative Variables",
    "text": "Quantitative Variables\nWe have analyzed a quantitative variable already. Where?\nIn the Colombia COVID data!\n\n\ndf_CO = pd.read_csv(\"http://dlsun.github.io/pods/data/covid/colombia_2020-05-28.csv\")\ndf_CO\n\n            Departamento  Edad  ... Fecha de diagnóstico Fecha recuperado\n0            Bogotá D.C.    19  ...           2020-03-06       2020-03-13\n1        Valle del Cauca    34  ...           2020-03-09       2020-03-19\n2              Antioquia    50  ...           2020-03-09       2020-03-15\n3              Antioquia    55  ...           2020-03-11       2020-03-26\n4              Antioquia    25  ...           2020-03-11       2020-03-23\n...                  ...   ...  ...                  ...              ...\n25361  Buenaventura D.E.    48  ...           2020-05-28              NaN\n25362    Valle del Cauca    55  ...           2020-05-28              NaN\n25363  Buenaventura D.E.    39  ...           2020-05-28              NaN\n25364    Valle del Cauca    13  ...           2020-05-28              NaN\n25365            Córdoba     0  ...           2020-05-28              NaN\n\n[25366 rows x 10 columns]",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#option-1-convert-it-to-categorical",
    "href": "slides/03-quantitative-variables.html#option-1-convert-it-to-categorical",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Option 1: Convert it to categorical",
    "text": "Option 1: Convert it to categorical\nTo visualize the age variable, we did the following:\n\ndf_CO[\"age\"] = pd.cut(\n    df_CO[\"Edad\"],\n    bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 120],\n    labels = [\"0-9\", \"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80+\"],\n    right = False, \n    ordered = True)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#option-1-then-make-a-barplot",
    "href": "slides/03-quantitative-variables.html#option-1-then-make-a-barplot",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Option 1: Then make a barplot",
    "text": "Option 1: Then make a barplot\nThen, we could treat age as categorical and make a barplot:\n\n\n\nCode\n(\n  ggplot(df_CO, aes(x = \"age\")) + \n  geom_bar() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#option-2-treat-it-as-a-quantitative-variable",
    "href": "slides/03-quantitative-variables.html#option-2-treat-it-as-a-quantitative-variable",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Option 2: Treat it as a quantitative variable!",
    "text": "Option 2: Treat it as a quantitative variable!\nA histogram uses equal sized bins to summarize a quantitative variable.\n\n\n\nCode\n(\n  ggplot(df_CO, aes(x = \"Edad\")) + \n  geom_histogram() + \n  labs(x = \"\", \n       y = \"\", \n       title = \"Age Demographics of Columbia's Population (2020)\"\n       ) +\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#changing-binwidth",
    "href": "slides/03-quantitative-variables.html#changing-binwidth",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Changing Binwidth",
    "text": "Changing Binwidth\nTo tweak your histogram, you can change the binwith:\n\n\n\n\n\n(\n  ggplot(df_CO, aes(x = \"Edad\")) + \n  geom_histogram(binwidth = 1) + \n  labs(x = \"\", \n       y = \"\", \n       title = \"Age Demographics of Columbia's Population (2020)\"\n       ) +\n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(\n  ggplot(df_CO, aes(x = \"Edad\")) + \n  geom_histogram(binwidth = 10) + \n  labs(x = \"\", \n       y = \"\", \n       title = \"Age Demographics of Columbia's Population (2020)\"\n       ) +\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#adding-color-outline",
    "href": "slides/03-quantitative-variables.html#adding-color-outline",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Adding Color & Outline",
    "text": "Adding Color & Outline\n\n\n\nCode\n(\n  ggplot(df_CO, aes(x = \"Edad\")) + \n  geom_histogram(binwidth = 10, \n                 color = \"white\", \n                 fill = \"gray\") + \n  labs(x = \"\", \n       y = \"\", \n       title = \"Age Demographics of Columbia's Population (2020)\"\n       ) +\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#using-percents-instead-of-counts",
    "href": "slides/03-quantitative-variables.html#using-percents-instead-of-counts",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Using Percents Instead of Counts",
    "text": "Using Percents Instead of Counts\n\n\n\nCode\n(\n  ggplot(df_CO, mapping = aes(x = \"Edad\")) + \n  geom_histogram(mapping = aes(y = '..density..'), \n                 binwidth = 10, \n                 color = \"white\", \n                 fill = \"gray\") + \n  labs(x = \"\", \n       y = \"\", \n       title = \"Age Demographics of Columbia's Population (2020)\"\n       ) +\n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#distributions",
    "href": "slides/03-quantitative-variables.html#distributions",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Distributions",
    "text": "Distributions\n\nRecall the distribution of a categorical variable:\n\nWhat are the possible values and how common is each?\n\nThe distribution of a quantitative variable is similar:\n\nThe total area in the histogram is 1.0 (or 100%).",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#densities",
    "href": "slides/03-quantitative-variables.html#densities",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Densities",
    "text": "Densities\n\n\nIn this example, we have a limited set of possible values for age: 0, 1, 2, …., 100.\n\nWe call this a discrete variable.\n\n\n\n\n\n\nWhat if had a quantitative variable with infinite values?\n\nFor example: Price of a ticket on Titanic.\nWe call this a continuous variable.\n\n\n\n\n\n\n\nIn this case, it is not possible to list all possible values and how likely each one is.\n\nOne person paid $2.35\nTwo people paid $12.50\nOne person paid $34.98\n\\(\\vdots\\)\n\n\n\n\n\n\n\nInstead, we talk about ranges of values.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#densities-1",
    "href": "slides/03-quantitative-variables.html#densities-1",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Densities",
    "text": "Densities\nAbout what percent of people in this dataset are below 18?\n\n\n\nCode\n(\n  ggplot(data = df_CO, mapping = aes(x = \"Edad\")) + \n  geom_histogram(mapping = aes(y = '..density..'), \n                 bins = 10) + \n  geom_vline(xintercept = 18, \n             color = \"red\", \n             size = 2, \n             linetype = \"dashed\") +\n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\nHow would you code it?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#mean",
    "href": "slides/03-quantitative-variables.html#mean",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Mean",
    "text": "Mean\n\n\nOne summary of the center of a quantitative variable is the mean.\nWhen you hear “The average age is…” or the “The average income is…”, this probably refers to the mean.\nSuppose we have five people, ages: 4, 84, 12, 27, 7\nThe mean age is: \\[(4 + 84 + 12 + 27 + 7) / 5 = 134 / 5 = 26.8\\]",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#notation-interlude",
    "href": "slides/03-quantitative-variables.html#notation-interlude",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Notation Interlude",
    "text": "Notation Interlude\n\n\n\nTo refer to our data without having to list all the numbers, we use \\(x_1, x_2, ..., x_n\\)\nIn the previous example, \\(x_1 = 4, x_2 = 84, x_3 = 12, x_4 = 27, x_5 = 7\\). So, \\(n = 5\\).\nTo add up all the numbers, we use the summation notation: \\[ \\sum_{i = 1}^5 x_i = 134\\]\nTherefore, the mean is: \\[\\bar{x} = \\frac{1}{n} \\sum_{i = 1}^n x_i\\]",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#means-in-python",
    "href": "slides/03-quantitative-variables.html#means-in-python",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Means in Python",
    "text": "Means in Python\nLong version: find the sum and the number of observations\n\nsum_age = df_CO[\"Edad\"].sum()\nn = len(df_CO)\n\nsum_age / n\n\nnp.float64(39.04742568792872)\n\n\n\nShort version: use the built-in .mean() function!\n\ndf_CO[\"Edad\"].mean()\n\nnp.float64(39.04742568792872)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#activity-2.1",
    "href": "slides/03-quantitative-variables.html#activity-2.1",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Activity 2.1",
    "text": "Activity 2.1\nThe mean is only one option for summarizing the center of a quantitative variable. It isn’t perfect!\nLet’s investigate this.\n\nOpen the Activity 2.1 Collab notebook\nRead in the Titanic data\nPlot the density of ticket prices on titanic\nCalculate the mean price\nSee how many people paid more than mean price",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#what-happened",
    "href": "slides/03-quantitative-variables.html#what-happened",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "What happened",
    "text": "What happened\n\nOur fare data was skewed right: Most values were small, but a few values were very large.\nThese large values “pull” the mean up; just how the value 84 pulled the average age up in our previous example.\nSo, why do we like the mean?",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#squared-error",
    "href": "slides/03-quantitative-variables.html#squared-error",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Squared Error",
    "text": "Squared Error\n\n\nRecall: Ages 4, 84, 12, 27, 7.\n\n\nages = np.array([4, 84, 12, 27, 7])\n\n\nImagine that we had to “guess” the age of the next person.\n\n\n\n\n\n\n\nIf we guess 26.8, then our “squared error” for these five people is:\n\n\nsq_error = (ages - 26.8) ** 2\n\n(\n  sq_error\n  .round(decimals = 1)\n  .sum()\n  )\n\nnp.float64(4402.6)\n\n\n\n\n\n\n\n\n\n\nIf we guess 20, then our “squared error” for these five people is:\n\n\nsq_error = (ages - 20) ** 2\n(\n  sq_error\n  .round(decimals = 1)\n  .sum()\n  )\n\nnp.int64(4634)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#minimizing-squared-error",
    "href": "slides/03-quantitative-variables.html#minimizing-squared-error",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Minimizing squared error",
    "text": "Minimizing squared error\n\n\n\nCode\ncs = range(1, 60)\nsum_squared_distances = []\n\nfor c in cs:\n  (\n    sum_squared_distances\n    .append(\n      (\n        (df_CO[\"Edad\"] - c) ** 2\n      )\n      .sum()\n      )\n\nres_df = pd.DataFrame({\"center\": cs, \"sq_error\": sum_squared_distances})\n\n(\n  ggplot(res_df, aes(x = 'center', y = 'sq_error')) + \n  geom_line() +\n  labs(x = \"Mean\", \n       y = \"\", \n       title = \"Changes in Sum of Squared Error Based on Choice of Center\")\n  )",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#median",
    "href": "slides/03-quantitative-variables.html#median",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Median",
    "text": "Median\n\nAnother summary of center is the median, which is the “middle” of the sorted values.\nTo calculate the median of a quantitative variable with values \\(x_1, x_2, x_3, ..., x_n\\), we do the following steps:\n\n\n\n\nSort the values from smallest to largest: \\[x_{(1)}, x_{(2)}, x_{(3)}, ..., x_{(n)}.\\]\nThe “middle” value depends on whether we have an odd or an even number of observations.\n\nIf \\(n\\) is odd, then the middle value is \\(x_{(\\frac{n + 1}{2})}\\).\nIf \\(n\\) is even, then there are two middle values, \\(x_{(\\frac{n}{2})}\\) and \\(x_{(\\frac{n}{2} + 1)}\\).\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is conventional to report the mean of the two values (but you can actually pick any value between them)!",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#median-in-python",
    "href": "slides/03-quantitative-variables.html#median-in-python",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Median in Python",
    "text": "Median in Python\nAges: 4, 84, 12, 7, 27. What is the median?\nMedian age in the Columbia data:\n\ndf_CO[\"Edad\"].median()\n\nnp.float64(37.0)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#variance",
    "href": "slides/03-quantitative-variables.html#variance",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Variance",
    "text": "Variance\n\n\n\nOne measure of spread is the variance.\nThe variance of a variable whose values are \\(x_1, x_2, x_3, ..., x_n\\) is calculated using the formula \\[\\textrm{var(X)} = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})^2}{n - 1}\\]\n\n\n\n\n\n\n\n\n\n\nDoes this look familiar?\n\n\nIt’s the sum of squared error! Well, divided by \\(n-1\\), the “degrees of freedom”.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#variance-in-python",
    "href": "slides/03-quantitative-variables.html#variance-in-python",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Variance in Python",
    "text": "Variance in Python\nSimilar to calculating the mean, we could find the variance manually:\n\n(\n  ((df_CO[\"Edad\"] - df_CO[\"Edad\"].mean()) ** 2)\n  .sum() / (len(df_CO) - 1)\n  )\n\nnp.float64(348.0870469898451)\n\n\n\n…or using a built-in Python function.\n\ndf_CO[\"Edad\"].var()\n\nnp.float64(348.0870469898451)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#standard-deviation",
    "href": "slides/03-quantitative-variables.html#standard-deviation",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Standard Deviation",
    "text": "Standard Deviation\n\n\nNotice that the variance isn’t very intuitive. What do we mean by “The spread is 348”?\nThis is because it is the squared error!\n\n\n\n\n\nTo get it in more interpretable language, we can take the square root:\n\n\nnp.sqrt(df_CO[\"Edad\"].var())\n\nnp.float64(18.65709106452142)\n\n\n\n\n\n\nOr, we use the built-in function!\n\ndf_CO[\"Edad\"].std()\n\nnp.float64(18.65709106452142)",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/03-quantitative-variables.html#takeaway-messages",
    "href": "slides/03-quantitative-variables.html#takeaway-messages",
    "title": "Visualizing and Summarizing Quantitative Variables",
    "section": "Takeaway Messages",
    "text": "Takeaway Messages\n\n\n\nVisualize quantitative variables with histograms or densities.\nSummarize the center of a quantitative variable with mean or median.\nDescribe the shape of a quantitative variable with skew.\nSummarize the spread of a quantitative variable with the variance or the standard deviation.",
    "crumbs": [
      "Lecture Slides",
      "Week 2, Part 1 - Visualizing and Summarizing Quantitative Variables"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#data-are-stored-in-plain-text-files",
    "href": "slides/01-tabular-data-summaries.html#data-are-stored-in-plain-text-files",
    "title": "Tabular Data and Variable Summaries",
    "section": "Data are stored in plain text files",
    "text": "Data are stored in plain text files\n\nname,pclass,survived,sex,age,sibsp,parch,ticket,fare,cabin,embarked,boat,body,home.dest\n\"Allen, Miss. Elisabeth Walton\",1,1,female,29,0,0,24160,211.3375,B5,S,2,,\"St Louis, MO\"\n\"Allison, Master. Hudson Trevor\",1,1,male,0.9167,1,2,113781,151.5500,C22 C26,S,11,,\"Montreal, PQ / Chesterville, ON\"\n\"Allison, Miss. Helen Loraine\",1,0,female,2,1,2,113781,151.5500,C22 C26,S,,,\"Montreal, PQ / Chesterville, ON\"\n\"Allison, Mr. Hudson Joshua Creighton\",1,0,male,30,1,2,113781,151.5500,C22 C26,S,,135,\"Montreal, PQ / Chesterville, ON\"\n\"Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\",1,0,female,25,1,2,113781,151.5500,C22 C26,S,,,\"Montreal, PQ / Chesterville, ON\"\n\"Anderson, Mr. Harry\",1,1,male,48,0,0,19952,26.5500,E12,S,3,,\"New York, NY\"\n\"Andrews, Miss. Kornelia Theodosia\",1,1,female,63,1,0,13502,77.9583,D7,S,10,,\"Hudson, NY\"\n\"Andrews, Mr. Thomas Jr\",1,0,male,39,0,0,112050,0.0000,A36,S,,,\"Belfast, NI\"\n\"Appleton, Mrs. Edward Dale (Charlotte Lamson)\",1,1,female,53,2,0,11769,51.4792,C101,S,D,,\"Bayside, Queens, NY\"\n\"Artagaveytia, Mr. Ramon\",1,0,male,71,0,0,PC 17609,49.5042,,C,,22,\"Montevideo, Uruguay\"\n\"Astor, Col. John Jacob\",1,0,male,47,1,0,PC 17757,227.5250,C62 C64,C,,124,\"New York, NY\"\n\n\n\nThis is called a csv (comma-separated) file.\nYou might see it stored as something.csv or something.txt\n.txt files might have different delimiters (separators)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#reading-data",
    "href": "slides/01-tabular-data-summaries.html#reading-data",
    "title": "Tabular Data and Variable Summaries",
    "section": "Reading data",
    "text": "Reading data\nWe read the data into a program like Python by specifying:\n\nwhat type of file it is (e.g., .csv, .txt, .xlsx)\nwhere the csv file is located (the “path”)\nif the file has a header\n… and other information in special cases!",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#example-using-pandas-data-frame",
    "href": "slides/01-tabular-data-summaries.html#example-using-pandas-data-frame",
    "title": "Tabular Data and Variable Summaries",
    "section": "Example using pandas data frame:",
    "text": "Example using pandas data frame:\n\ndf = pd.read_csv(\"https://datasci112.stanford.edu/data/titanic.csv\")\n\n\n\n\n\n\n\nread_csv() lives in pandas\n\n\n\n\n\n\n\n\ndf.head()\n\n\n\n\n                                              name  ...                        home.dest\n0                    Allen, Miss. Elisabeth Walton  ...                     St Louis, MO\n1                   Allison, Master. Hudson Trevor  ...  Montreal, PQ / Chesterville, ON\n2                     Allison, Miss. Helen Loraine  ...  Montreal, PQ / Chesterville, ON\n3             Allison, Mr. Hudson Joshua Creighton  ...  Montreal, PQ / Chesterville, ON\n4  Allison, Mrs. Hudson J C (Bessie Waldo Daniels)  ...  Montreal, PQ / Chesterville, ON\n\n[5 rows x 14 columns]",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#lecture-1.1-check-in",
    "href": "slides/01-tabular-data-summaries.html#lecture-1.1-check-in",
    "title": "Tabular Data and Variable Summaries",
    "section": "Lecture 1.1 Check in",
    "text": "Lecture 1.1 Check in\n\n\ndf = pd.read_csv(\"https://datasci112.stanford.edu/data/titanic.csv\")\n\n\n\n\n\nQuestion 1: What if this file lived on a computer instead of online?\nQuestion 2: Why didn’t we have to specify that this dataset has a header?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#looking-at-the-rows",
    "href": "slides/01-tabular-data-summaries.html#looking-at-the-rows",
    "title": "Tabular Data and Variable Summaries",
    "section": "Looking at the rows",
    "text": "Looking at the rows\n\n\n\n\ndf.loc[1, :]\n\nname          Allison, Master. Hudson Trevor\npclass                                     1\nsurvived                                   1\nsex                                     male\nage                                   0.9167\nsibsp                                      1\nparch                                      2\nticket                                113781\nfare                                  151.55\ncabin                                C22 C26\nembarked                                   S\nboat                                      11\nbody                                     NaN\nhome.dest    Montreal, PQ / Chesterville, ON\nName: 1, dtype: object\n\n\n\n\n\n\n\n\ndf.iloc[1, :]\n\nname          Allison, Master. Hudson Trevor\npclass                                     1\nsurvived                                   1\nsex                                     male\nage                                   0.9167\nsibsp                                      1\nparch                                      2\nticket                                113781\nfare                                  151.55\ncabin                                C22 C26\nembarked                                   S\nboat                                      11\nbody                                     NaN\nhome.dest    Montreal, PQ / Chesterville, ON\nName: 1, dtype: object\n\n\n\n\n\n\nWhat is the difference between .loc and .iloc?\nWhat type of object is returned?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#loc-iloc-and-index",
    "href": "slides/01-tabular-data-summaries.html#loc-iloc-and-index",
    "title": "Tabular Data and Variable Summaries",
    "section": "loc, iloc, and index",
    "text": "loc, iloc, and index\n\ndf2 = df.set_index('name')\n\n\n\n\n                                                 pclass  ...                        home.dest\nname                                                     ...                                 \nAllen, Miss. Elisabeth Walton                         1  ...                     St Louis, MO\nAllison, Master. Hudson Trevor                        1  ...  Montreal, PQ / Chesterville, ON\nAllison, Miss. Helen Loraine                          1  ...  Montreal, PQ / Chesterville, ON\nAllison, Mr. Hudson Joshua Creighton                  1  ...  Montreal, PQ / Chesterville, ON\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)       1  ...  Montreal, PQ / Chesterville, ON\n\n[5 rows x 13 columns]\n\n\n\n\n\n\n\n\n\n\nWhy are there 13 columns now? (There were 14 before!)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#loc-iloc-and-index-1",
    "href": "slides/01-tabular-data-summaries.html#loc-iloc-and-index-1",
    "title": "Tabular Data and Variable Summaries",
    "section": "loc, iloc, and index",
    "text": "loc, iloc, and index\n\n\n\ndf2.loc[1, :]\n\nKeyError: 1\n\n\n\n\n\n\ndf2.iloc[1, :]\n\npclass                                     1\nsurvived                                   1\nsex                                     male\nage                                   0.9167\nsibsp                                      1\nparch                                      2\nticket                                113781\nfare                                  151.55\ncabin                                C22 C26\nembarked                                   S\nboat                                      11\nbody                                     NaN\nhome.dest    Montreal, PQ / Chesterville, ON\nName: Allison, Master. Hudson Trevor, dtype: object\n\n\n\n\n\n\nWhy is .loc returning an error?\n\n\n\n\n\nWhy is .iloc not returning an error?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#loc-iloc-and-index-2",
    "href": "slides/01-tabular-data-summaries.html#loc-iloc-and-index-2",
    "title": "Tabular Data and Variable Summaries",
    "section": "loc, iloc, and index",
    "text": "loc, iloc, and index\n\n\n.loc – label-based location\n\n\nUses labels from rows (rownames) to select data\n\n\n\ndf2.loc[\"Allison, Master. Hudson Trevor\", :]\n\npclass                                     1\nsurvived                                   1\nsex                                     male\nage                                   0.9167\nsibsp                                      1\nparch                                      2\nticket                                113781\nfare                                  151.55\ncabin                                C22 C26\nembarked                                   S\nboat                                      11\nbody                                     NaN\nhome.dest    Montreal, PQ / Chesterville, ON\nName: Allison, Master. Hudson Trevor, dtype: object\n\n\n\n\n\n\n\n\n.iloc – integer location\n\n\nUses indices (positions) from rows to select data\n\n\n\ndf2.iloc[1, :]\n\npclass                                     1\nsurvived                                   1\nsex                                     male\nage                                   0.9167\nsibsp                                      1\nparch                                      2\nticket                                113781\nfare                                  151.55\ncabin                                C22 C26\nembarked                                   S\nboat                                      11\nbody                                     NaN\nhome.dest    Montreal, PQ / Chesterville, ON\nName: Allison, Master. Hudson Trevor, dtype: object",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#looking-at-columns",
    "href": "slides/01-tabular-data-summaries.html#looking-at-columns",
    "title": "Tabular Data and Variable Summaries",
    "section": "Looking at columns",
    "text": "Looking at columns\n\n\n\ndf.columns\n\nIndex(['name', 'pclass', 'survived', 'sex', 'age', 'sibsp', 'parch', 'ticket',\n       'fare', 'cabin', 'embarked', 'boat', 'body', 'home.dest'],\n      dtype='object')\n\n\n\n\n\n\n\ndf['home.dest']\n\n0                          St Louis, MO\n1       Montreal, PQ / Chesterville, ON\n2       Montreal, PQ / Chesterville, ON\n3       Montreal, PQ / Chesterville, ON\n4       Montreal, PQ / Chesterville, ON\n                     ...               \n1304                                NaN\n1305                                NaN\n1306                                NaN\n1307                                NaN\n1308                                NaN\nName: home.dest, Length: 1309, dtype: object\n\n\n\n\n\n\n\n\n\n\n\nNaN (Not a Number) represents missing or null data",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#caution-object-types",
    "href": "slides/01-tabular-data-summaries.html#caution-object-types",
    "title": "Tabular Data and Variable Summaries",
    "section": "Caution: Object types",
    "text": "Caution: Object types\n\ntype(df)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\n\n\n\n\n\ntype(df.iloc[1, :])\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\ntype(df['name'])\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n\n\n\n\n\nA Series is a one-dimensional labeled array (a vector with labels)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#questions-to-ask",
    "href": "slides/01-tabular-data-summaries.html#questions-to-ask",
    "title": "Tabular Data and Variable Summaries",
    "section": "Questions to ask",
    "text": "Questions to ask\n\nWhich variables (columns) are categorical?\nWhich variables are quantitative?\nWhich variables are labels (e.g. names or ID numbers)?\nWhich variables are text?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#a-quick-look-at-the-data",
    "href": "slides/01-tabular-data-summaries.html#a-quick-look-at-the-data",
    "title": "Tabular Data and Variable Summaries",
    "section": "A quick look at the data",
    "text": "A quick look at the data\n\n\ndf.describe()\n\n            pclass     survived  ...         fare        body\ncount  1309.000000  1309.000000  ...  1308.000000  121.000000\nmean      2.294882     0.381971  ...    33.295479  160.809917\nstd       0.837836     0.486055  ...    51.758668   97.696922\nmin       1.000000     0.000000  ...     0.000000    1.000000\n25%       2.000000     0.000000  ...     7.895800   72.000000\n50%       3.000000     0.000000  ...    14.454200  155.000000\n75%       3.000000     1.000000  ...    31.275000  256.000000\nmax       3.000000     1.000000  ...   512.329200  328.000000\n\n[8 rows x 7 columns]\n\n\n\n\nLecture 1.1 Check in\n\n\n\nQuestion 3: What percent of Titanic passengers survived?\nQuestion 4: What was the average (mean) fare paid for a ticket?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#changing-variable-types",
    "href": "slides/01-tabular-data-summaries.html#changing-variable-types",
    "title": "Tabular Data and Variable Summaries",
    "section": "Changing Variable Types",
    "text": "Changing Variable Types\n\nThe variable pclass was categorical, but Python assumed it was quantitative.\nIt’s our job to check and fix data!\n\n\n\ndf[\"pclass\"] = df[\"pclass\"].astype(\"category\")\n\n\n\n\n\n\n\n\n\n\nWhy choose to store pclass as a \"category\" instead of a \"string\"?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#summary-of-categorical-variable",
    "href": "slides/01-tabular-data-summaries.html#summary-of-categorical-variable",
    "title": "Tabular Data and Variable Summaries",
    "section": "Summary of categorical variable",
    "text": "Summary of categorical variable\n\ndf[\"pclass\"].value_counts()\n\npclass\n3    709\n1    323\n2    277\nName: count, dtype: int64\n\n\n\n\n\ndf[\"pclass\"].value_counts(normalize = True)\n\npclass\n3    0.541635\n1    0.246753\n2    0.211612\nName: proportion, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/01-tabular-data-summaries.html#lecture-1.1-check-in-2",
    "href": "slides/01-tabular-data-summaries.html#lecture-1.1-check-in-2",
    "title": "Tabular Data and Variable Summaries",
    "section": "Lecture 1.1 Check in",
    "text": "Lecture 1.1 Check in\nQuestion 5: What percent of Titanic passengers were in First Class?\nQuestion 6: Which is the correct way to change a numeric column to a categorical variable?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 1 - Tabular Data and Variable Summaries"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#about-me",
    "href": "slides/00-welcome.html#about-me",
    "title": "Welcome, Intro, and Setup",
    "section": "About Me",
    "text": "About Me\n\n\n\n\n\n\nGrew up in Grand Junction, CO\nBA in Stats: 2014 from Colorado Mesa University\nPhD in Stats: 2020 from Montana State University\n2020 - now: Professor of Stats at Cal Poly\nMy research: Statistics and data science education, R programming\nThings I like: Spending time outside (e.g., running, hiking, biking), travelling, going to concerts and musicals",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#grade-brakedown",
    "href": "slides/00-welcome.html#grade-brakedown",
    "title": "Welcome, Intro, and Setup",
    "section": "Grade Brakedown",
    "text": "Grade Brakedown\n\n5%: Check-Ins – Questions interspersed throughout lecture\n10%: Lab Activities – Lab attendance is required\n25%: Weekly Assignments – due Saturdays at midnight\n15% each: Exams in Week 5 and Week 10.\n30%: Final project",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#important-dates",
    "href": "slides/00-welcome.html#important-dates",
    "title": "Welcome, Intro, and Setup",
    "section": "Important Dates",
    "text": "Important Dates\n\nThurs, February 6: Exam 1 (in-class)\nFri, February 21: 1-page Project Proposal Due\nThurs, March 13: Exam 2 (in-class)\nSaturday, March 16 (before Finals Week: Final Project Poster Presentations",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#homework-late-policy",
    "href": "slides/00-welcome.html#homework-late-policy",
    "title": "Welcome, Intro, and Setup",
    "section": "Homework Late Policy",
    "text": "Homework Late Policy\n\nTwo deadline extensions: Fill out the form on Canvas before the deadline, get an automatic 3-day (72-hour) deadline extension.\nIf you’ve used your deadline extensions, late work has a 10% deduction per day for up to 5 days.\n\nThis policy also applies to deadline extension requests that are not submitted before the assignment’s deadline.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#missing-lab",
    "href": "slides/00-welcome.html#missing-lab",
    "title": "Welcome, Intro, and Setup",
    "section": "Missing Lab",
    "text": "Missing Lab\n\nBest option: Go to another section.\nSecond-best option: Turn in your work by email to me.\nWorst option: Miss it entirely, get a 0.\nYou may miss lab up to two times during the quarter. If you need to miss / reschedule more than two of the labs this quarter, you will need to retake the class.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#discord-and-email",
    "href": "slides/00-welcome.html#discord-and-email",
    "title": "Welcome, Intro, and Setup",
    "section": "Discord and Email",
    "text": "Discord and Email\n\nClass questions go on DISCORD\nUse my email only for personal concerns that you want to talk about privately to me.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#colab-notebooks",
    "href": "slides/00-welcome.html#colab-notebooks",
    "title": "Welcome, Intro, and Setup",
    "section": "Colab Notebooks",
    "text": "Colab Notebooks\n\nIn Data Science, everyone uses Notebooks, not scripts, for coding.\nWe will be using Jupyter Notebooks (invented at Cal Poly!), hosted for free by Google Colab.\nIf you want to work offline, you can install Anaconda on your laptop.\nI recommend an IDE like PyCharm (or Positron) as well.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#academic-integrity",
    "href": "slides/00-welcome.html#academic-integrity",
    "title": "Welcome, Intro, and Setup",
    "section": "Academic Integrity",
    "text": "Academic Integrity\n\nIf you copy text from a website into your essay, it’s cheating.\nIf you ask your friend to write your essay, it’s cheating.\nIf you pay someone else to write your essay, it’s cheating.\nIf you ask GenAI to do your work and then copy the answers, it’s cheating.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#conversation-not-copying",
    "href": "slides/00-welcome.html#conversation-not-copying",
    "title": "Welcome, Intro, and Setup",
    "section": "Conversation, not copying",
    "text": "Conversation, not copying\nIt is okay (in fact, encouraged) to …\n\nAsk GenAI for tips on how to get started on a coding problem\nAsk GenAI to help find bugs in your code\nAsk GenAI to help explain concepts or functions\nPretend ChatGPT is your human tutor or TA!",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "slides/00-welcome.html#activity-good-and-bad-use-of-ai",
    "href": "slides/00-welcome.html#activity-good-and-bad-use-of-ai",
    "title": "Welcome, Intro, and Setup",
    "section": "Activity: Good and bad use of AI",
    "text": "Activity: Good and bad use of AI\n\nFind your group member\n\nIn the “People” tab on Canvas, find your “Day 1 Group”\n\nOnce you have found your group member, open the Activity 1.1 notebook (linked on Canvas).\n\n\n15-minutes:\n\nFirst, Person A follows the instructions in Part 1 of the notebook.\nThen, Person B follows the instructions in Part 2 of the notebook.\nFinally, discuss and answer the questions at the bottom.\n\n\n\n\n\n\n\n\n\nIf it is not your turn to type, you watch!\n\n\nDo not give input unless your partner asks for help.",
    "crumbs": [
      "Lecture Slides",
      "Week 0 - Welcome & Course Set-up"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Data Science (in Python)",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the quarter. Note that this schedule will be updated as the quarter progresses, with all changes documented here.\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nRequired Reading\nLecture Slides\nLab Activity\nWeekly Assignment\nExams & Project\n\n\n\n\n0\nSunday, January 5\n\nWelcome to DATA 301!\n\n\n\n\n\n1 Summarizing Tabular Data\nTuesday, January 7\n\nTabular Data & Variable Summaries\nGenAI Activity (Link to Collab)\nActivity 1.1 (Link to Collab)\n\n\n\n\n\nThursday, January 9\n\nVisualizing and Comparing Categorical Variables\nActivity 1.2 (Link to Collab)\nLab 1A\nLab 1B\n\n\n\n\nFriday, January 10\n\n\n\nLab 1 Due by Midnight\n\n\n\n2 Summarizing & Visualizing Quantitative Data\nTuesday, January 14\n(Dr. T’s b-day)\n\nVisualizing and Summarizing Quantitative Variables\nActivity 2.1 (Link to Collab)\n\n\n\n\n\nThursday, January 16\n\nMultivariate Summaries\nActivity 2.2\nLab 2A\nLab 2B\n\n\n\n\nFriday, January 17\n\n\n\nLab 2 Due by Midnight\n\n\n\n3\nMeasuring Similarity with Distances\nTuesday, January 21\nNo Class (Classes Follow Monday Schedule)\n\n\n\n\n\n\n\nThursday, January 23\n\nDistances Between Observations\n\nLecture Activity 3.1\nActivity 3.1\nLab 3\n\n\n\n\nFriday, January 24\n\n\n\nLab 3 Due by Midnight\n\n\n\n4\nDummy Variables & TF-IDF\nTuesday, January 28\n\nDummy Variables and Column Transformers\nActivity 4.1\n\n\n\n\n\nThursday, January 30\n\nBag-of-words and TF-IDF\nActivity 4.2\nLab 4A\nLab 4B\n\n\n\n\nFriday, January 31\n\n\n\nLab 4 Due by Midnight\n\n\n\n5\nK-Nearest Neighbors, Intro to Modeling & Midterm Exam\nTuesday, February 4\n\nK-Nearest-Neighbors\nActivity 5.1\n\n\n\n\n\nThursday, February 6\n\nIntroduction to Modeling\nActivity 5.2\n\nMidterm Exam (in-class)\n\n\n\nFriday, February 7\n\n\n\nLab 5 Due by Midnight\n\n\n\n6\nClassification & Model Selection\nTuesday, February 11\n\nCross-Validation and Grid Search\nActivity 6.1\n\n\n\n\n\nThursday, February 13\n\nClassification\nActivity 6.2\n\n\n\n\n\nFriday, February 14\n\n\n\nLab 6 Due by Midnight\n\n\n\n7\nLogistic Regression & Unsupervised Learning\nTuesday, February 18\n\nLogistic Regression\nActivity 7.1\n\n\n\n\n\nThursday, February 20\n\nUnsupervised Learning with K-Means\nActivity 7.2\n\n\n\n\n\nFriday, February 21\n\n\n\nLab 7 Due by Midnight\nProject Proposal Due\n\n\n8\nJoining Data & Hierarchical Data\nTuesday, February 25\n\nCombining Datasets\nActivity 8.1\n\n\n\n\n\nThursday, February 27\n\nHierarchical Data\nActivity 8.2\n\n\n\n\n\nFriday, February 28\n\n\n\nLab 8 Due by Midnight\n\n\n\n9\nWebscraping\nTuesday, March 4\n\nWebscraping\nActivity 9.1\n\n\n\n\n\nThursday, March 6\n\n\nActivity 9.2\n\n\n\n\n\nFriday, March 7\n\n\n\nLab 9 Due by Midnight\n\n\n\n10\nFinal Posters & Final Exam\nTuesday, March 11\n\n\n\n\nPosters Due to be Printed\n\n\n\nThursday, March 13\n\n\n\n\nFinal Exam (in-class)\n\n\nFinals Week\nSaturday, March 15 10:10am - 1pm\n\n\n\n\nPoster Presentations",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#course-objectives",
    "href": "course-materials/syllabus.html#course-objectives",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Course Objectives",
    "text": "Course Objectives\nAfter taking this course, you will be able to:\n\nAcquire and process tabular, textual, hierarchical, and geospatial data.\nUncover patterns by summarizing and visualizing data.\nApply machine learning to answer real-world prediction problems.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#prerequisites",
    "href": "course-materials/syllabus.html#prerequisites",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Prerequisites",
    "text": "Prerequisites\nI expect you to enter this class with:\n\nBasic knowledge of Python and computer programming concepts.\nFamiliarity with computers and technology (e.g., Internet browsing, word processing, opening/saving files, converting files to PDF format, sending and receiving e-mail, etc.).\nA positive attitude, a curious mind, and a respect for ethical use of data science tools.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#lecture-check-ins-5",
    "href": "course-materials/syllabus.html#lecture-check-ins-5",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Lecture Check-Ins (5%)",
    "text": "Lecture Check-Ins (5%)\nEvery lecture will be accompanied by a simple “Check-In Quiz” on Canvas. This will ask you to input a few answers covered in lecture, and one short mid-lecture practice exercise. Infinite submissions are allowed without penalty, so there is no reason anyone should not get 100% in this category.\nIf you miss lecture, you can still complete the Check-Ins on your own time, by midnight the next day.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#lab-attendance-and-activities-10",
    "href": "course-materials/syllabus.html#lab-attendance-and-activities-10",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Lab Attendance and Activities (10%)",
    "text": "Lab Attendance and Activities (10%)\nAttendance and participation in the lab portion of class is required. Do not take this class if you cannot commit to attending every lecture and every lab.\n\nSwapping Lab Sections\nIf you cannot make it to your assigned lab, but you can attend another section’s lab on the same day, please e-mail Dr. Theobold to inform them that you wish to swap lab sections. You may do this two times throughout the quarter.\n\n\nMissing Lab\nIf you cannot make it to any lab sections that day, you may complete the Colab assignment from lab on your own, and e-mail a PDF to Dr. Theobold by midnight that night (the day you missed class). Dr. Theobold will grade your Colab, and this score will replace your attendance for that day. You may do this two times throughout the quarter.\nTo allow for emergencies, we will also forgive one absence at the end of the quarter.\n\n\n\n\n\n\nNote\n\n\n\nWe are effectively allowing you to miss / reschedule up to three labs out of 10. If you need to miss more than three, then you will need to retake this course next quarter.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#lab-assignments-25",
    "href": "course-materials/syllabus.html#lab-assignments-25",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Lab Assignments (25%)",
    "text": "Lab Assignments (25%)\nEach week, you will be assigned longer homeworks, which will ask you to analyze a real-world data scenario. These assignments are due every Saturday at 11:59pm. See the Late Work section below for information on extensions or deductions for late submissions.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#exams-15-each",
    "href": "course-materials/syllabus.html#exams-15-each",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Exams (15% each)",
    "text": "Exams (15% each)\nYou will have two in-class exams, in Week 5 and Week 10. These will each cover half of the class material. Except in very extreme unforeseeable circumstances, no alternate exams will be given; please plan to be in class these days.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#project-30",
    "href": "course-materials/syllabus.html#project-30",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Project (30%)",
    "text": "Project (30%)\nAt the end of the quarter, you will formally present a poster of your findings on a real-world data question. To ensure that you start thinking about your project early, you are required to submit a 1-page abstract proposal in Week 7.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#communication",
    "href": "course-materials/syllabus.html#communication",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Communication",
    "text": "Communication\nFor questions of general interest, such as deadline clarifications or conceptual questions, please use the Class Discord Server. You should check the relevant thread of the server, as well as the syllabus, before reaching out to Dr. Theobold.\nOf course, if your question is truly private, such as a grade inquiry or a personal concern, you may email me directly.\n\n\n\n\n\n\nNote\n\n\n\nIf you email me to ask a question that should be public, I will likely ask you to post your question on Discord instead. Please don’t take this personally! It just means that you asked a good question, and I think the rest of the class could benefit from seeing the answer.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#late-work",
    "href": "course-materials/syllabus.html#late-work",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Late Work",
    "text": "Late Work\nLate assignments will automatically be docked -10% per day, up to a maximum grade penalty of 50%. That is, as long as your work is turned in by the end of Week 10, you will still get half credit for it!\n\n\n\n\n\n\nNote\n\n\n\nNote that turning in an assignment late means you will not get any feedback, and using lecture or section time to work on late assignments will not be tolerated.\n\n\n\nDeadline Extensions\nIn case of emergency, you have two deadline “extensions” to use throughout the quarter on any Lab Assignment. This will grant you a 72-hour (3-day) extension.\nThe rules for these are as follows:\n\nYou must request the extension through the Google form linked on Canvas. Any other request (e.g., by email, Discord message, verbally, etc.) does not count unless the Google form is filled out.\nThe extension must be requested before the deadline has passed (i.e., before Friday at 11:59pm). I do not grant after-deadline extensions for any reason.\n\nProperly requested extensions are automatically granted; you will not get a confirmation email or message, you will simply see your late penalties disappear at some point.\n\n\n\n\n\n\nNote\n\n\n\nThese deadline extensions are automatic! You don’t have to tell why you need the extension - maybe you have a busy week with other work, maybe you are traveling with a sports team, maybe you partied too hard for your friend’s birthday. It doesn’t matter to me!\nThe flip side of this, though, is that if you use your deadline extensions early on in the course, and then run into a bigger issues later on, you’re out of luck.\n\n\n\n\nSpecial cases\nSometimes, issues arise require more time than the auto-extension gives. In general, if something comes up in your life, I always want to find a way to help. Please let me know what your situation is, and we’ll work together to find a good solution.\nThe most important thing is that you tell me early. As a rule, I do not grant extensions after the deadline.\n\n\n\n\n\n\nNote\n\n\n\nOf course, in the case of a major crisis, that is truly exceptional and unforeseen, all these rules go out the window. I want you to feel comfortable reaching out to me when you are facing something extra difficult. We’ll figure it out.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#academic-integrity",
    "href": "course-materials/syllabus.html#academic-integrity",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nYou are expected to abide by the Cal Poly Code of Conduct at all times.\n\nPlagiarism\nYou are encouraged to work with other classmates on all but the exam portions of this class. You are also encouraged (realistically, required!) to make use of online resources to accomplish tasks.\nWhen dealing with code, follow these guidelines:\n\nNever copy-paste more than small snippets of code. That is, you might borrow a little three-line function from StackOverflow, but you should not copy over a full analysis you find on Kaggle.\nAttribute all code that is not completely your own. If you do borrow that StackOverflow snippet, provide a link to the source. If you reference a similar analysis for ideas, mention that in your description.\n\n\n\n\n\n\n\nWarning\n\n\n\nA good “rule of thumb” is: If I sat you down by yourself in a room with no internet, could you explain to me roughly what each line of code is doing? If not, you are probably borrowing more than you should from your online source.\n(In fact, this is exactly what I will do if I need to investigate possible cheating.)\n\n\n\nAI tools\nNew AI models like Chat GPT offer a whole new world of online coding resources. This is exciting! You should absolutely feel free to get help from these tools, they are excellent at answering questions.\nHowever, from an academic integrity perspective, treat these AI generative chat resources like, say, a tutor. Asking a tutor to help explain a homework concept to you or help debug your code? Totally fine! Giving the tutor a homework question and having them answer the whole thing? Nope. Talking to a tutor at all, about anything, during the course of the exam? Unacceptable.\n\n\n\nIntegrity Violations\nIf you accidentally forget a small citation, or go a little overboard in how much you “borrow” from StackOverflow, you’ll get a warning and a grade deduction on that assignment.\nAny instance of willful and deliberate cheating will result in a failing grade on the assignment and I will file a academic integrity report with the Office of Student Rights and responsibilities.\n\n\n\n\n\n\nWarning\n\n\n\nBe careful about being on the giving end as well as the taking end. For example: If you send your finished assignment to a friend, and that friend copies it, you have both received a failing grade on the assignment and a report filed to OSRR.\n\n\n\n\nIntellectual property\nThe materials for this course are legally the professor’s intellectual property.\nMost class materials are publicly shared, and you are welcome to direct others to this resource at any time. You are also welcome to publicly share any or all of your work on the class project.\nNon-public class materials—most importantly, assignment solutions and any exam materials—may never be shared.\n\n\n\n\n\n\nWarning\n\n\n\nThis is not just an issue of academic honestly, it is quite literally a legal copyright scenario. Please do not distribute solutions or exam questions from this class anywhere, for any reason. Doing so is a violation of the Code of Conduct, and it may constitute a violation of U.S. copyright law.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-materials/syllabus.html#class-conduct",
    "href": "course-materials/syllabus.html#class-conduct",
    "title": "DATA 301: Introduction to Data Science",
    "section": "Class Conduct",
    "text": "Class Conduct\nIn this classroom, I expect you to be polite, respectful, inclusive, and open-minded.\nSome examples of how to be a good classmate include:\n\nDoing your best to avoid language that is ableist, racist, sexist, transphobic, or classist; or that perpetuates harmful stereotypes.\nAddressing your classmates (and your professor!) by their preferred name and pronouns.\nDoing your best to be aware of your own biases, privileges, and areas of ignorance.\nListening to others’ opinions, and making an effort to understand their perspective.\nTaking the time to help your classmates grasp concepts or solve problems, even when you are ready to move on.\n\n\nAttendance\nIt is my general expectation that you will attend lecture, and remain present until you have finished the day’s in-class work. However, I do not take formal attendance in class; as long as you engage with the material and complete the small check-ins, you can decide which lectures are useful to you.\nPlease do not email me letting me know when you are missing class - I don’t need to know if you are attending, it is your responsibility to catch up on the materials and check-ins you miss.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "slides/05-distances.html#summarizing",
    "href": "slides/05-distances.html#summarizing",
    "title": "Distances Between Observations",
    "section": "Summarizing",
    "text": "Summarizing\n\nOne categorical variable: marginal distribution\nTwo categorical variables: joint and conditional distributions\nOne quantitative variable: mean, median, variance, standard deviation.\nOne quantitative, one categorical: mean, median, and std dev across groups (groupby(), split-apply-combine)\nTwo quantitative variables: z-scores, correlation"
  },
  {
    "objectID": "slides/05-distances.html#visualizing",
    "href": "slides/05-distances.html#visualizing",
    "title": "Distances Between Observations",
    "section": "Visualizing",
    "text": "Visualizing\n\nOne categorical variable: bar plot or column plot\nTwo categorical variables: stacked bar plot, side-by-side bar plot, or stacked percentage bar plot\nOne quantitative variable: histogram, density plot, or boxplot\nOne quantitative, one categorical: overlapping densities, side-by-side boxplots, or facetting\nTwo quantitative variables: scatterplot"
  },
  {
    "objectID": "slides/05-distances.html#ames-house-prices",
    "href": "slides/05-distances.html#ames-house-prices",
    "title": "Distances Between Observations",
    "section": "Ames house prices",
    "text": "Ames house prices\n\n\ndf = pd.read_table(\"https://datasci112.stanford.edu/data/housing.tsv\",\n                    sep = \"\\\\t\")\ndf.head()\n\n         PID  Gr Liv Area  Bedroom AbvGr  ...  Sale Type  Sale Condition  SalePrice\n0  526301100         1656              3  ...        WD           Normal     215000\n1  526350040          896              2  ...        WD           Normal     105000\n2  526351010         1329              3  ...        WD           Normal     172000\n3  526353030         2110              3  ...        WD           Normal     244000\n4  527105010         1629              3  ...        WD           Normal     189900\n\n[5 rows x 81 columns]\n\n\n\n\n\n\n\n\nread_table not read_csv\n\n\nThis is a tsv file (tab separated values), so we need to use a different function to read in our data! The sep argument allows you to specify the delimiter the file uses, but you can also allow the system to autodetect the delimiter."
  },
  {
    "objectID": "slides/05-distances.html#how-does-house-size-relate-to-number-of-bedrooms",
    "href": "slides/05-distances.html#how-does-house-size-relate-to-number-of-bedrooms",
    "title": "Distances Between Observations",
    "section": "How does house size relate to number of bedrooms?",
    "text": "How does house size relate to number of bedrooms?\n\n\n\n\nCode\n(\n  ggplot(df, mapping = aes(x = \"Gr Liv Area\", y = \"Bedroom AbvGr\"))  + \n  geom_point() +\n  labs(x = \"Total Living Area\", \n       y = \"Number of Bedrooms\")\n )"
  },
  {
    "objectID": "slides/05-distances.html#how-does-house-size-relate-to-number-of-bedrooms-1",
    "href": "slides/05-distances.html#how-does-house-size-relate-to-number-of-bedrooms-1",
    "title": "Distances Between Observations",
    "section": "How does house size relate to number of bedrooms?",
    "text": "How does house size relate to number of bedrooms?\nWhat statistic would you calculate?\n\n\ndf[[\"Gr Liv Area\", \"Bedroom AbvGr\"]].corr()\n\n               Gr Liv Area  Bedroom AbvGr\nGr Liv Area       1.000000       0.516808\nBedroom AbvGr     0.516808       1.000000"
  },
  {
    "objectID": "slides/05-distances.html#similarity",
    "href": "slides/05-distances.html#similarity",
    "title": "Distances Between Observations",
    "section": "Similarity",
    "text": "Similarity\nHow might we answer the question, “Are these two houses similar?”\n\n\n\n\ndf.loc[1707, [\"Gr Liv Area\", \"Bedroom AbvGr\"]]\n\nGr Liv Area      2956\nBedroom AbvGr       5\nName: 1707, dtype: object\n\n\n\n\n\n\n\n\ndf.loc[290, [\"Gr Liv Area\", \"Bedroom AbvGr\"]]\n\nGr Liv Area      2650\nBedroom AbvGr       6\nName: 290, dtype: object"
  },
  {
    "objectID": "slides/05-distances.html#distance",
    "href": "slides/05-distances.html#distance",
    "title": "Distances Between Observations",
    "section": "Distance",
    "text": "Distance\nThe distance between the two observations is:\n\\[ \\sqrt{ (2956 - 2650)^2 + (5 - 6)^2} = 306 \\]\n\n… what does this number mean? Not much!\nBut we can use it to compare sets of houses and find houses that appear to be the most similar."
  },
  {
    "objectID": "slides/05-distances.html#another-house-to-consider",
    "href": "slides/05-distances.html#another-house-to-consider",
    "title": "Distances Between Observations",
    "section": "Another House to Consider",
    "text": "Another House to Consider\n\n\n\ndf.loc[1707, [\"Gr Liv Area\", \"Bedroom AbvGr\"]]\n\nGr Liv Area      2956\nBedroom AbvGr       5\nName: 1707, dtype: object\n\n\n\n\n\n\ndf.loc[291, [\"Gr Liv Area\", \"Bedroom AbvGr\"]]\n\nGr Liv Area      1666\nBedroom AbvGr       3\nName: 291, dtype: object\n\n\n\n\n\\[ \\sqrt{ (2956 - 1666)^2 + (5 - 3)^2} = 1290 \\]\nThus, house 1707 is more similar to house 290 than to house 291."
  },
  {
    "objectID": "slides/05-distances.html#lecture-activity-part-1",
    "href": "slides/05-distances.html#lecture-activity-part-1",
    "title": "Distances Between Observations",
    "section": "Lecture Activity Part 1",
    "text": "Lecture Activity Part 1\n\nComplete Part One of the activity linked in Canvas.\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/05-distances.html#house-160-seems-more-similar",
    "href": "slides/05-distances.html#house-160-seems-more-similar",
    "title": "Distances Between Observations",
    "section": "House 160 seems more similar…",
    "text": "House 160 seems more similar…\n\n\n\nCode\n(\n  ggplot(df, mapping = aes(y = \"Gr Liv Area\", x = \"Bedroom AbvGr\")) + \n  geom_point(color = \"lightgrey\") + \n  geom_point(df.loc[[1707]], color = \"red\", size = 2, shape = 17) + \n  geom_point(df.loc[[160]], color = \"blue\", size = 2) + \n  geom_point(df.loc[[2336]], color = \"green\", size = 2) + \n  theme_bw() +\n  labs(y = \"Total Living Area (Square Feet)\", \n       x = \"Number of Bedrooms\")\n)"
  },
  {
    "objectID": "slides/05-distances.html#even-if-we-zoom-in",
    "href": "slides/05-distances.html#even-if-we-zoom-in",
    "title": "Distances Between Observations",
    "section": "…even if we zoom in…",
    "text": "…even if we zoom in…\n\n\n\nCode\n(\n  ggplot(df, mapping = aes(y = \"Gr Liv Area\", x = \"Bedroom AbvGr\")) + \n  geom_point(color = \"lightgrey\") + \n  geom_point(df.loc[[1707]], color = \"red\", size = 5, shape = \"x\") + \n  geom_point(df.loc[[160]], color = \"blue\", size = 2) + \n  geom_point(df.loc[[2336]], color = \"green\", size = 2) + \n  theme_bw() +\n  labs(y = \"Total Living Area (Square Feet)\", \n       x = \"Number of Bedrooms\") +\n  scale_y_continuous(limits = (2500, 3500))\n)"
  },
  {
    "objectID": "slides/05-distances.html#but-not-if-we-put-the-axes-on-the-same-scale",
    "href": "slides/05-distances.html#but-not-if-we-put-the-axes-on-the-same-scale",
    "title": "Distances Between Observations",
    "section": "…but not if we put the axes on the same scale!",
    "text": "…but not if we put the axes on the same scale!\n\n\n\nCode\n(\n  ggplot(df, aes(y = \"Gr Liv Area\", x = \"Bedroom AbvGr\")) + \n  geom_point(color = \"lightgrey\") + \n  geom_point(df.loc[[1707]], color = \"red\", size = 5, shape = \"x\") + \n  geom_point(df.loc[[160]], color = \"blue\", size = 2) + \n  geom_point(df.loc[[2336]], color = \"green\", size = 2) + \n  theme_bw() +\n  labs(y = \"Total Living Area (Square Feet)\", \n       x = \"Number of Bedrooms\") +\n  scale_y_continuous(limits = (2900, 3000)) +\n  scale_x_continuous(limits = (0, 100))\n)"
  },
  {
    "objectID": "slides/05-distances.html#scaling",
    "href": "slides/05-distances.html#scaling",
    "title": "Distances Between Observations",
    "section": "Scaling",
    "text": "Scaling\nWe need to make sure our features are on the same scale before we can use distances to measure similarity.\n\n\n\n\n\n\nStandardizing\n\n\nsubtract the mean, divide by the standard deviation"
  },
  {
    "objectID": "slides/05-distances.html#scaling-1",
    "href": "slides/05-distances.html#scaling-1",
    "title": "Distances Between Observations",
    "section": "Scaling",
    "text": "Scaling\n\n\ndf['size_scaled'] = (df['Gr Liv Area'] - df['Gr Liv Area'].mean()) / df['Gr Liv Area'].std()\ndf['bdrm_scaled'] = (df['Bedroom AbvGr'] - df['Bedroom AbvGr'].mean()) / df['Bedroom AbvGr'].std()\n\n\n\n\n\nCode\n(\n  ggplot(df, aes(y = \"size_scaled\", x = \"bdrm_scaled\")) + \n  geom_point(color = \"lightgrey\") + \n  geom_point(df.loc[[1707]], color = \"red\", size = 5, shape = \"x\") + \n  geom_point(df.loc[[160]], color = \"blue\", size = 2) + \n  geom_point(df.loc[[2336]], color = \"green\", size = 2) + \n  theme_bw() +\n  labs(y = \"Total Living Area (Standardized)\", \n       x = \"Number of Bedrooms (Standardized)\") \n)"
  },
  {
    "objectID": "slides/05-distances.html#lecture-activity-part-2",
    "href": "slides/05-distances.html#lecture-activity-part-2",
    "title": "Distances Between Observations",
    "section": "Lecture Activity Part 2",
    "text": "Lecture Activity Part 2\n\nComplete Part Two of the activity linked in Canvas.\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/05-distances.html#scikit-learn-1",
    "href": "slides/05-distances.html#scikit-learn-1",
    "title": "Distances Between Observations",
    "section": "Scikit-learn",
    "text": "Scikit-learn\n\nscikit-learn is a library for machine learning and modeling\nWe will use it a lot in this class!\nFor now, we will use it as a shortcut for scaling and for computing distances\n\n\n\nThe philosophy of sklearn is:\n\nspecify your analysis\nfit on the data to prepare the analysis\ntransform the data"
  },
  {
    "objectID": "slides/05-distances.html#specify",
    "href": "slides/05-distances.html#specify",
    "title": "Distances Between Observations",
    "section": "Specify",
    "text": "Specify\n\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nscaler\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScaler?Documentation for StandardScaleriNot fittedStandardScaler() \n\n\nNo calculations have happened yet!"
  },
  {
    "objectID": "slides/05-distances.html#fit",
    "href": "slides/05-distances.html#fit",
    "title": "Distances Between Observations",
    "section": "Fit",
    "text": "Fit\nThe scaler object “learns” the means and standard deviations.\n\n\ndf_orig = df[['Gr Liv Area', 'Bedroom AbvGr']]\nscaler.fit(df_orig)\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScaler?Documentation for StandardScaleriFittedStandardScaler() \n\nscaler.mean_\n\narray([1499.69044369,    2.85426621])\n\nscaler.scale_\n\narray([505.4226158 ,   0.82758988])\n\n\n\n\nWe still have not altered the data at all!"
  },
  {
    "objectID": "slides/05-distances.html#transform",
    "href": "slides/05-distances.html#transform",
    "title": "Distances Between Observations",
    "section": "Transform",
    "text": "Transform\n\ndf_scaled = scaler.transform(df_orig)\ndf_scaled\n\narray([[ 0.30926506,  0.17609421],\n       [-1.19442705, -1.03223376],\n       [-0.33771825,  0.17609421],\n       ...,\n       [-1.04801492,  0.17609421],\n       [-0.21900572, -1.03223376],\n       [ 0.9898836 ,  0.17609421]], shape=(2930, 2))"
  },
  {
    "objectID": "slides/05-distances.html#sklearn-numpy-and-pandas",
    "href": "slides/05-distances.html#sklearn-numpy-and-pandas",
    "title": "Distances Between Observations",
    "section": "sklearn, numpy, and pandas",
    "text": "sklearn, numpy, and pandas\n\n\nBy default, sklearn functions return numpy objects.\nThis is sometimes annoying, maybe we want to plot things after scaling.\nSolution: remake it, with the original column names.\n\n\n\n\n\npd.DataFrame(df_scaled, columns = df_orig.columns)\n\n      Gr Liv Area  Bedroom AbvGr\n0        0.309265       0.176094\n1       -1.194427      -1.032234\n2       -0.337718       0.176094\n3        1.207523       0.176094\n4        0.255844       0.176094\n...           ...            ...\n2925    -0.982723       0.176094\n2926    -1.182556      -1.032234\n2927    -1.048015       0.176094\n2928    -0.219006      -1.032234\n2929     0.989884       0.176094\n\n[2930 rows x 2 columns]"
  },
  {
    "objectID": "slides/05-distances.html#distances-with-sklearn",
    "href": "slides/05-distances.html#distances-with-sklearn",
    "title": "Distances Between Observations",
    "section": "Distances with sklearn",
    "text": "Distances with sklearn\n\nfrom sklearn.metrics import pairwise_distances\n\npairwise_distances(df_scaled[[1707]], df_scaled)\n\narray([[3.52929876, 5.45459713, 4.0252646 , ..., 4.61305666, 4.76999349,\n        3.06886734]], shape=(1, 2930))"
  },
  {
    "objectID": "slides/05-distances.html#finding-the-most-similar",
    "href": "slides/05-distances.html#finding-the-most-similar",
    "title": "Distances Between Observations",
    "section": "Finding the Most Similar",
    "text": "Finding the Most Similar\n\n\n\n\ndists = pairwise_distances(df_scaled[[1707]], \n                           df_scaled)\ndists.argsort()\n\narray([[1707,  160,  909, ...,  158, 2723, 2279]], shape=(1, 2930))\n\n\n\n\n\n\n\n\nbest = (\n  dists\n  .argsort()\n  .flatten()\n  [1:10]\n  )\n  \ndf_orig.iloc[best]\n\n      Gr Liv Area  Bedroom AbvGr\n160          2978              5\n909          3082              5\n1288         2792              5\n2350         2784              5\n253          3222              5\n2592         2640              5\n585          2640              5\n2027         2526              5\n2330         3390              5"
  },
  {
    "objectID": "slides/05-distances.html#lecture-activity-part-3",
    "href": "slides/05-distances.html#lecture-activity-part-3",
    "title": "Distances Between Observations",
    "section": "Lecture Activity Part 3",
    "text": "Lecture Activity Part 3\n\nComplete Part Three of the activity linked in Canvas.\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/05-distances.html#other-scaling",
    "href": "slides/05-distances.html#other-scaling",
    "title": "Distances Between Observations",
    "section": "Other scaling",
    "text": "Other scaling\n\nStandardization \\[x_i \\leftarrow \\frac{x_i - \\bar{X}}{\\text{sd}(X)}\\]\nMin-Max Scaling \\[x_i \\leftarrow \\frac{x_i - \\text{min}(X)}{\\text{max}(X) - \\text{min}(X)}\\]"
  },
  {
    "objectID": "slides/05-distances.html#other-distances",
    "href": "slides/05-distances.html#other-distances",
    "title": "Distances Between Observations",
    "section": "Other distances",
    "text": "Other distances\n\nEuclidean (\\(\\ell_2\\))\n\\[\\sqrt{\\sum_{j=1}^m (x_j - x'_j)^2}\\]\nManhattan (\\(\\ell_1\\))\n\\[\\sum_{j=1}^m |x_j - x'_j|\\]"
  },
  {
    "objectID": "slides/05-distances.html#lecture-activity-part-4",
    "href": "slides/05-distances.html#lecture-activity-part-4",
    "title": "Distances Between Observations",
    "section": "Lecture Activity Part 4",
    "text": "Lecture Activity Part 4\n\nComplete Part Four of the activity linked in Canvas.\n\n\n\n\n−+\n10:00"
  },
  {
    "objectID": "slides/05-distances.html#takeaways-1",
    "href": "slides/05-distances.html#takeaways-1",
    "title": "Distances Between Observations",
    "section": "Takeaways",
    "text": "Takeaways\n\nWe measure similarity between observations by calculating distances.\nIt is important that all our features be on the same scale for distances to be meaningful.\nWe can use scikit-learn functions to fit and transform data, and to compute pairwise distances.\nThere are many options of ways to scale data; most common is standardizing\nThere are many options of ways to measure distances; most common is Euclidean distance."
  },
  {
    "objectID": "slides/02-conditional-distributions.html#getting-and-prepping-data",
    "href": "slides/02-conditional-distributions.html#getting-and-prepping-data",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "df = pd.read_csv(\"https://datasci112.stanford.edu/data/titanic.csv\")\n\n\ndf[\"pclass\"] = df[\"pclass\"].astype(\"category\")\ndf[\"survived\"] = df[\"survived\"].astype(\"category\")",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#thinking-about-variable-types",
    "href": "slides/02-conditional-distributions.html#thinking-about-variable-types",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "name\npclass\nsurvived\nsex\nage\nsibsp\nparch\nticket\nfare\ncabin\nembarked\nboat\nbody\nhome.dest\n\n\n\n\nAllen, Miss. Elisabeth Walton\n1\n1\nfemale\n29.0000\n0\n0\n24160\n211.3375\nB5\nS\n2\nNaN\nSt Louis, MO\n\n\nAllison, Master. Hudson Trevor\n1\n1\nmale\n0.9167\n1\n2\n113781\n151.5500\nC22 C26\nS\n11\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Miss. Helen Loraine\n1\n0\nfemale\n2.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Mr. Hudson Joshua Creighton\n1\n0\nmale\n30.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\n135\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\n1\n0\nfemale\n25.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAnderson, Mr. Harry\n1\n1\nmale\n48.0000\n0\n0\n19952\n26.5500\nE12\nS\n3\nNaN\nNew York, NY",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#accessing-rows-and-columns",
    "href": "slides/02-conditional-distributions.html#accessing-rows-and-columns",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "df.iloc[5,]\n\nname         Anderson, Mr. Harry\npclass                         1\nsurvived                       1\nsex                         male\nage                         48.0\nsibsp                          0\nparch                          0\nticket                     19952\nfare                       26.55\ncabin                        E12\nembarked                       S\nboat                           3\nbody                         NaN\nhome.dest           New York, NY\nName: 5, dtype: object\n\n\n\n\ndf[\"name\"].head()\n\n0                      Allen, Miss. Elisabeth Walton\n1                     Allison, Master. Hudson Trevor\n2                       Allison, Miss. Helen Loraine\n3               Allison, Mr. Hudson Joshua Creighton\n4    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\nName: name, dtype: object",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#quick-summary-of-quantitative-variables",
    "href": "slides/02-conditional-distributions.html#quick-summary-of-quantitative-variables",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "df.describe()\n\n               age        sibsp        parch         fare        body\ncount  1046.000000  1309.000000  1309.000000  1308.000000  121.000000\nmean     29.881135     0.498854     0.385027    33.295479  160.809917\nstd      14.413500     1.041658     0.865560    51.758668   97.696922\nmin       0.166700     0.000000     0.000000     0.000000    1.000000\n25%      21.000000     0.000000     0.000000     7.895800   72.000000\n50%      28.000000     0.000000     0.000000    14.454200  155.000000\n75%      39.000000     1.000000     0.000000    31.275000  256.000000\nmax      80.000000     8.000000     9.000000   512.329200  328.000000",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#summarizing-categorical-variables",
    "href": "slides/02-conditional-distributions.html#summarizing-categorical-variables",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "The list of percents for each category is called the distribution of the variable.\n\ndf[\"pclass\"].value_counts()\n\npclass\n3    709\n1    323\n2    277\nName: count, dtype: int64\n\ndf[\"pclass\"].value_counts(normalize = True)\n\npclass\n3    0.541635\n1    0.246753\n2    0.211612\nName: proportion, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#the-grammar-of-graphics",
    "href": "slides/02-conditional-distributions.html#the-grammar-of-graphics",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "The Grammar of Graphics",
    "text": "The Grammar of Graphics\nThe grammar of graphics is a framework for creating data visualizations.\n\n\n\nA visualization consists of:\n\nThe aesthetic: Which variables are dictating which plot elements.\nThe geometry: What shape of plot you are making.\nThe theme: Other choices about the appearance.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#example",
    "href": "slides/02-conditional-distributions.html#example",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Example",
    "text": "Example\n\n\n\n\nimport pandas as pd\nfrom palmerpenguins import load_penguins\nfrom plotnine import ggplot, geom_point, aes, geom_boxplot\n\npenguins = load_penguins()\n\n(\n  ggplot(data = penguins, mapping = aes(x = \"species\", \n                                        y = \"bill_length_mm\", \n                                        fill = \"sex\")\n        ) +\n  geom_boxplot()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n. . .\n\n\nAesthetics\nWhere are variables mapped to aspects of the plot?\n\n\nGeometry\nWhat shape(s) are used to represent the data / observations?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#plotnine",
    "href": "slides/02-conditional-distributions.html#plotnine",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "plotnine",
    "text": "plotnine\nThe plotnine library implements the grammar of graphics in Python.\n\nThe aes() function is the place to map variables to plot aesthetics.\n\nx, y, and fill are three possible aesthetics that can be specified\n\nA variety of geom_XXX() functions allow for different plotting shapes (e.g. boxplot, histogram, etc.)\n\nAesthetics can differ based on the geom you choose!",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#themes",
    "href": "slides/02-conditional-distributions.html#themes",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Themes",
    "text": "Themes\n\n\n\n\n\nCode\n(\n  ggplot(data = penguins, mapping = aes(x = \"species\", \n                                        y = \"bill_length_mm\", \n                                        fill = \"sex\")\n         ) + \n  geom_boxplot()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom plotnine import theme_bw\n\n(\n  ggplot(penguins, aes(x = \"species\", \n                       y = \"bill_length_mm\", \n                       fill = \"sex\")\n                       ) + \n  geom_boxplot() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#check-in",
    "href": "slides/02-conditional-distributions.html#check-in",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Check-In",
    "text": "Check-In\nWhat are the aesthetics and geometry in the cartoon plot below?\n\n\n\nAn XKCD comic",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#bar-plots",
    "href": "slides/02-conditional-distributions.html#bar-plots",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Bar Plots",
    "text": "Bar Plots\nTo visualize the distribution of a categorical variable, we should use a bar plot.\n\n\n\nCode\nfrom plotnine import *\n\n(\n  ggplot(data = df, mapping = aes(x = \"pclass\")) + \n  geom_bar() + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#calculating-percents",
    "href": "slides/02-conditional-distributions.html#calculating-percents",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Calculating Percents",
    "text": "Calculating Percents\n\npclass_dist = (\n  df['pclass']\n  .value_counts(normalize = True)\n  .reset_index()\n  )\n  \npclass_dist\n\n  pclass  proportion\n0      3    0.541635\n1      1    0.246753\n2      2    0.211612",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#percents-on-plots",
    "href": "slides/02-conditional-distributions.html#percents-on-plots",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Percents on Plots",
    "text": "Percents on Plots\n\n\n\nCode\n(\n  ggplot(data = pclass_dist, \n         mapping = aes(x = \"pclass\", y = \"proportion\")) + \n  geom_col() + ### notice this change to a column plot!\n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTechnically, you could still use geom_bar(), but you would need to specify that you didn’t want it to use stat = \"count\" (the default). You’ve already calculated the proportions, so you would use geom_bar(stat = \"identity\").",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-1-stacked-bar-plot",
    "href": "slides/02-conditional-distributions.html#option-1-stacked-bar-plot",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 1: Stacked Bar Plot",
    "text": "Option 1: Stacked Bar Plot\n\n\n\nCode\n(\n  ggplot(data = df, mapping = aes(x = \"pclass\", fill = \"sex\")) + \n  geom_bar(position = \"stack\") + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-1-stacked-bar-plot-1",
    "href": "slides/02-conditional-distributions.html#option-1-stacked-bar-plot-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 1: Stacked Bar Plot",
    "text": "Option 1: Stacked Bar Plot\n\nWhat are some pros and cons of the stacked bar plot?\n\n\n\n\nPros\n\n\nWe can still see the total counts in each class\nWe can easily compare the male counts in each class, since those bars are on the bottom.\n\n\n\n\n\n\n\nCons\n\n\nIt is hard to compare the female counts, since those bars are stacked on top.\nIt is hard to estimate the distributions.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-2-side-by-side-bar-plot",
    "href": "slides/02-conditional-distributions.html#option-2-side-by-side-bar-plot",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 2: Side-by-Side Bar Plot",
    "text": "Option 2: Side-by-Side Bar Plot\n\n\n\nCode\n(\n  ggplot(data = df, mapping = aes(x = \"pclass\", fill = \"sex\")) + \n  geom_bar(position = \"dodge\") + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-2-side-by-side-bar-plot-1",
    "href": "slides/02-conditional-distributions.html#option-2-side-by-side-bar-plot-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 2: Side-by-side Bar Plot",
    "text": "Option 2: Side-by-side Bar Plot\n\nWhat are some pros and cons of the side-by-side bar plot?\n\n\n\n\nPros\n\n\nWe can easily compare the female counts in each class.\nWe can easily compare the male counts in each class.\nWe can easily see counts of each within each class.\n\n\n\n\n\n\n\nCons\n\n\nIt is hard to see total counts in each class.\nIt is hard to estimate the distributions.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-3-stacked-percentage-bar-plot",
    "href": "slides/02-conditional-distributions.html#option-3-stacked-percentage-bar-plot",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 3: Stacked Percentage Bar Plot",
    "text": "Option 3: Stacked Percentage Bar Plot\n\n\n\nCode\n(\n  ggplot(data = df, mapping = aes(x = \"pclass\", fill = \"sex\")) + \n  geom_bar(position = \"fill\") + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#option-3-stacked-percentage-bar-plot-1",
    "href": "slides/02-conditional-distributions.html#option-3-stacked-percentage-bar-plot-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Option 3: Stacked Percentage Bar Plot",
    "text": "Option 3: Stacked Percentage Bar Plot\n\nWhat are some pros and cons of the stacked percentage bar plot?\n\n\n\n\nPros\n\n\nThis is the best way to compare sex balance across classes!\nThis is the option I use the most, because it can answer “Are you more likely to find ______ in ______ ?” type questions.\n\n\n\n\n\n\n\nCons\n\n\nWe can no longer see any counts!",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#activity-1.2",
    "href": "slides/02-conditional-distributions.html#activity-1.2",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Activity 1.2",
    "text": "Activity 1.2\n\nChoose one of the plots from lecture so far and “upgrade” it.\n\n\nYou can do this by:\n\nFinding and using a different theme\nUsing labs() to change the axis labels\nTrying different variables\nTrying a different geometries\nUsing + scale_fill_manual() to change the colors being used\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nYou will need to use documentation of plotnine and online resources!\nCheck out https://www.data-to-viz.com/ for ideas and example code.\nAsk GenAI questions like, “What do I add to a plotnine bar plot to change the colors?” (But of course, make sure you understand the code you use!)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#two-categorical-variables",
    "href": "slides/02-conditional-distributions.html#two-categorical-variables",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Two Categorical Variables",
    "text": "Two Categorical Variables\n\ndf[[\"pclass\", \"sex\"]].value_counts()\n\npclass  sex   \n3       male      493\n        female    216\n1       male      179\n2       male      171\n1       female    144\n2       female    106\nName: count, dtype: int64",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#two-way-table",
    "href": "slides/02-conditional-distributions.html#two-way-table",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Two-way Table",
    "text": "Two-way Table\n\n(\n  df[[\"pclass\", \"sex\"]]\n  .value_counts()\n  .unstack()\n  )\n\nsex     female  male\npclass              \n1          144   179\n2          106   171\n3          216   493\n\n\n\nThis is sometimes called a cross-tab or cross-tabulation.\n\n\n\n\n\n\nPivot Table\n\n\n\nEssentially unstack() has pivoted the sex column from long format (where the values are included in one column) to wide format where each value has its own column.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#two-way-table---percents",
    "href": "slides/02-conditional-distributions.html#two-way-table---percents",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Two-way Table - Percents",
    "text": "Two-way Table - Percents\n\n(\n  df[[\"pclass\", \"sex\"]]\n  .value_counts(normalize = True)\n  .unstack()\n  )\n\nsex       female      male\npclass                    \n1       0.110008  0.136746\n2       0.080978  0.130634\n3       0.165011  0.376623\n\n\n\nAll of these values should sum to 1, aka, 100%!",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#switching-variable-order",
    "href": "slides/02-conditional-distributions.html#switching-variable-order",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Switching Variable Order",
    "text": "Switching Variable Order\nWhat cross-tabulation would you expect if we changed the order of the variables? In other words, what would happen if \"sex\" came first and \"pclass\" came second?\n. . .\n\n\n(\n  df[[\"sex\", \"pclass\"]]\n  .value_counts(normalize = True)\n  .unstack()\n  )\n\npclass         1         2         3\nsex                                 \nfemale  0.110008  0.080978  0.165011\nmale    0.136746  0.130634  0.376623",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#interpretation",
    "href": "slides/02-conditional-distributions.html#interpretation",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Interpretation",
    "text": "Interpretation\nWe call this the joint distribution of the two variables.\n\n\nsex       female      male\npclass                    \n1       0.110008  0.136746\n2       0.080978  0.130634\n3       0.165011  0.376623\n\n\n\n\nOf all the passengers on the Titanic, 11% were female passengers riding in first class.\n\n. . .\n\nNOT “11% of all females on Titanic…”\nNOT “11% of all first class passengers…”",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#conditional-distribution-from-counts",
    "href": "slides/02-conditional-distributions.html#conditional-distribution-from-counts",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Conditional Distribution from Counts",
    "text": "Conditional Distribution from Counts\nWe know that:\n\n466 passengers identified as female\nOf those 466 passengers, 144 rode in first class\n\n. . .\nSo:\n\n144 / 466 = 31% of female identifying passengers rode in first class\n\nHere we conditioned on the passenger being female, and then looked at the conditional distribution of pclass.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#conditional-distribution-from-percentages",
    "href": "slides/02-conditional-distributions.html#conditional-distribution-from-percentages",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Conditional Distribution from Percentages",
    "text": "Conditional Distribution from Percentages\nWe know that:\n\n35.5% of all passengers identified as female\nOf those 35.5% of passengers, 11% rode in first class\n\nSo:\n\n0.11 / 0.355 = 31% of female identifying passengers rode in first class\n\nHere we conditioned on the passenger being female, and then looked at the conditional distribution of pclass.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#swapping-variables",
    "href": "slides/02-conditional-distributions.html#swapping-variables",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Swapping Variables",
    "text": "Swapping Variables\nWe know that:\n\n323 passengers rode in first class\nOf those 323 passengers, 144 identified as female\n\nSo:\n\n144 / 323 = 44.6% of first class passengers identified as female\n\nHere we conditioned on the passenger being in first class, and then looked at the conditional distribution of sex.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#which-one-to-condition-on",
    "href": "slides/02-conditional-distributions.html#which-one-to-condition-on",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Which one to condition on?",
    "text": "Which one to condition on?\nThis depends on the research question you are trying to answer.\n. . .\n\n“What class did most female identifying passengers ride in?”\n\n-&gt; Of all female passengers, what is the conditional distribution of class?\n. . .\n\n“What was the gender breakdown of first class?”\n\n-&gt; Of all first class passengers, what is the conditional distribution of sex?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#calculating-in-python",
    "href": "slides/02-conditional-distributions.html#calculating-in-python",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Calculating in Python",
    "text": "Calculating in Python\n\nWhen we study two variables, we call the individual one-variable distributions the marginal distribution of that variable.\n\n\n\n\nmarginal_class = (\n  df['pclass']\n  .value_counts(normalize = True)\n  )\n\n\n\nmarginal_class\n\npclass\n3    0.541635\n1    0.246753\n2    0.211612\nName: proportion, dtype: float64\n\n\n\n\n\n\nmarginal_sex = (\n  df['sex']\n  .value_counts(normalize = True)\n  )\n\n\n\nmarginal_sex\n\nsex\nmale      0.644003\nfemale    0.355997\nName: proportion, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#calculating-in-python-1",
    "href": "slides/02-conditional-distributions.html#calculating-in-python-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Calculating in Python",
    "text": "Calculating in Python\n\nWe need to divide the joint distribution (e.g. “11% of passengers were first class female”) by the marginal distribution of the variable we want to condition on (e.g. 35.5% of passengers were female).\n\n\njoint_class_sex = (\n  df[[\"pclass\", \"sex\"]]\n  .value_counts(normalize = True)\n  .unstack()\n  )\n  \njoint_class_sex.divide(marginal_sex)\n\nsex       female      male\npclass                    \n1       0.309013  0.212337\n2       0.227468  0.202847\n3       0.463519  0.584816",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#check-in-1",
    "href": "slides/02-conditional-distributions.html#check-in-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Check-In",
    "text": "Check-In\n\n\n\nmarginal_sex\n\nsex\nmale      0.644003\nfemale    0.355997\nName: proportion, dtype: float64\n\n\n\n\n\n\njoint_class_sex\n\nsex       female      male\npclass                    \n1       0.110008  0.136746\n2       0.080978  0.130634\n3       0.165011  0.376623\n\n\n\n\n\n\n\n\njoint_class_sex.divide(marginal_sex)\n\nsex       female      male\npclass                    \n1       0.309013  0.212337\n2       0.227468  0.202847\n3       0.463519  0.584816\n\n\n\n\n\nHow do you think divide() works?",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#check-in-2",
    "href": "slides/02-conditional-distributions.html#check-in-2",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Check-In",
    "text": "Check-In\nShould the rows or columns add up to 100%? Why?\n\n\nsex       female      male\npclass                    \n1       0.309013  0.212337\n2       0.227468  0.202847\n3       0.463519  0.584816",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#conditional-on-class",
    "href": "slides/02-conditional-distributions.html#conditional-on-class",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Conditional on Class",
    "text": "Conditional on Class\n\njoint_class_sex = (\n  df[[\"sex\", \"pclass\"]]\n  .value_counts(normalize = True)\n  .unstack()\n  )\n  \njoint_class_sex.divide(marginal_class)\n\npclass        1         2         3\nsex                                \nfemale  0.44582  0.382671  0.304654\nmale    0.55418  0.617329  0.695346",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#what-if-you-get-it-backwards",
    "href": "slides/02-conditional-distributions.html#what-if-you-get-it-backwards",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "What if you get it backwards?",
    "text": "What if you get it backwards?\n\njoint_class_sex = (\n  df[[\"pclass\", \"sex\"]]\n  .value_counts(normalize = True)\n  .unstack()\n  )\n  \njoint_class_sex.divide(marginal_class)\n\n         1   2   3  female  male\npclass                          \n1      NaN NaN NaN     NaN   NaN\n2      NaN NaN NaN     NaN   NaN\n3      NaN NaN NaN     NaN   NaN",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#which-plot-better-answers-the-question",
    "href": "slides/02-conditional-distributions.html#which-plot-better-answers-the-question",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Which plot better answers the question:",
    "text": "Which plot better answers the question:\n\n“Did women tend to ride in first class more than men?”\n\n\n\n\n\nCode\n(\n  ggplot(df, aes(x = \"pclass\", fill = \"sex\")) + \n  geom_bar(position = \"fill\") + \n  theme_bw()\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n(\n  ggplot(df, aes(x = \"sex\", fill = \"pclass)) + \n  geom_bar(position = \"fill\") + \n  theme_bw()\n)",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/02-conditional-distributions.html#takeaways-1",
    "href": "slides/02-conditional-distributions.html#takeaways-1",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "Takeaways",
    "text": "Takeaways\n\n\n\nWe use plotnine and the grammar of graphics to make visuals.\nFor two categorical variables, we might use a stacked bar plot, a side-by-side bar plot, or a stacked percentage bar plot - depending on what we are trying to show.\nThe joint distribution of two variables gives the percents in each subcategory.\nThe marginal distribution of a variable is its individual distribution.\nThe conditional distribution of a variable is its distribution among only one category of a different variable.\nWe calculate the conditional distribution by dividing the joint by the marginal.",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  },
  {
    "objectID": "slides/06-preprocessing.html#distances",
    "href": "slides/06-preprocessing.html#distances",
    "title": "Dummy Variables and Column Transformers",
    "section": "Distances",
    "text": "Distances\n\nWe measure similarity between observations by calculating distances.\n\n\n\nEuclidean distance: sum of squared differences, then square root\nManhattan distance: sum of absolute differences\n\n\n\n\n\n\n\n\n\nscikit-learn\n\n\nUse the pairwise_distances() function to get back a 2D numpy array of distances."
  },
  {
    "objectID": "slides/06-preprocessing.html#scaling",
    "href": "slides/06-preprocessing.html#scaling",
    "title": "Dummy Variables and Column Transformers",
    "section": "Scaling",
    "text": "Scaling\n\nIt is important that all our features be on the same scale for distances to be meaningful.\n\n\n\nStandardize: Subtract the mean (of the column) and divide by the standard deviation (of the column).\nMinMax: Subtract the minimum value, divide by the range.\n\n\n\n\n\n\n\n\n\nscikit-learn\n\n\nFollow the specify - fit - transform code structure. In the specify step, you should use the StandardScaler() or MinMaxScaler() functions."
  },
  {
    "objectID": "slides/06-preprocessing.html#recall-ames-housing-data",
    "href": "slides/06-preprocessing.html#recall-ames-housing-data",
    "title": "Dummy Variables and Column Transformers",
    "section": "Recall: AMES Housing data",
    "text": "Recall: AMES Housing data\n\n\ndf = pd.read_table(\"https://datasci112.stanford.edu/data/housing.tsv\")\nfeatures = [\"Gr Liv Area\", \"Bedroom AbvGr\", \"Full Bath\", \"Half Bath\", \"Bldg Type\", \"Neighborhood\"]\ndf[features].head()\n\n   Gr Liv Area  Bedroom AbvGr  Full Bath  Half Bath Bldg Type Neighborhood\n0         1656              3          1          0      1Fam        NAmes\n1          896              2          1          0      1Fam        NAmes\n2         1329              3          1          1      1Fam        NAmes\n3         2110              3          2          1      1Fam        NAmes\n4         1629              3          2          1      1Fam      Gilbert"
  },
  {
    "objectID": "slides/06-preprocessing.html#what-about-categorical-variables",
    "href": "slides/06-preprocessing.html#what-about-categorical-variables",
    "title": "Dummy Variables and Column Transformers",
    "section": "What about categorical variables?",
    "text": "What about categorical variables?\nSuppose we want to include the variable Bldg Type in our distance calculation…\n\ndf[\"Bldg Type\"].value_counts()\n\nBldg Type\n1Fam      2425\nTwnhsE     233\nDuplex     109\nTwnhs      101\n2fmCon      62\nName: count, dtype: int64\n\n\n\n\nThen we need a way to calculate \\((\\texttt{1Fam} - \\texttt{Twnhs} )^ 2\\)."
  },
  {
    "objectID": "slides/06-preprocessing.html#converting-to-binary",
    "href": "slides/06-preprocessing.html#converting-to-binary",
    "title": "Dummy Variables and Column Transformers",
    "section": "Converting to Binary",
    "text": "Converting to Binary\nLet’s instead think about a variable that summarizes whether an observation is a single family home or not.\n\ndf[\"is_single_fam\"] = df[\"Bldg Type\"] == \"1Fam\"\ndf[\"is_single_fam\"].value_counts()\n\nis_single_fam\nTrue     2425\nFalse     505\nName: count, dtype: int64\n\n\n\n\n\n\n\n\n\nWhat does a value of True represent? False?"
  },
  {
    "objectID": "slides/06-preprocessing.html#converting-to-binary-1",
    "href": "slides/06-preprocessing.html#converting-to-binary-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Converting to binary",
    "text": "Converting to binary\nRecall that True/False is the same as 1/0 for computers:\n\ndf[\"is_single_fam\"] = df[\"is_single_fam\"].astype(\"int\")\ndf[\"is_single_fam\"].value_counts()\n\nis_single_fam\n1    2425\n0     505\nName: count, dtype: int64\n\n\nWe call this a dummy variable or a one-hot-encoding."
  },
  {
    "objectID": "slides/06-preprocessing.html#now-we-can-do-math",
    "href": "slides/06-preprocessing.html#now-we-can-do-math",
    "title": "Dummy Variables and Column Transformers",
    "section": "Now we can do math!",
    "text": "Now we can do math!\nSpecify\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import pairwise_distances\n\nscaler = StandardScaler()\n\n\n\nFit\n\n\n\ndf_orig = df[['Gr Liv Area', 'Bedroom AbvGr', 'is_single_fam']]\nscaler.fit(df_orig)\n\n\nStandardScaler()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.StandardScaler?Documentation for StandardScaleriFittedStandardScaler() \n\n\n\n\n\nTransform\n\n\ndf_scaled = scaler.transform(df_orig)"
  },
  {
    "objectID": "slides/06-preprocessing.html#lets-reset-the-dataset-now",
    "href": "slides/06-preprocessing.html#lets-reset-the-dataset-now",
    "title": "Dummy Variables and Column Transformers",
    "section": "Let’s reset the dataset now…",
    "text": "Let’s reset the dataset now…\n\ndf = pd.read_table(\"https://datasci112.stanford.edu/data/housing.tsv\")"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-variables-1",
    "href": "slides/06-preprocessing.html#dummifying-variables-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying Variables",
    "text": "Dummifying Variables\n\n\n\nWhat if we don’t just want to study is_single_fam, but rather, all categories of the Bldg Type variable?\nIn principle, we just make dummy variables for each category: is_single_fam, is_twnhse, etc.\nEach category becomes one column, with 0’s and 1’s to show if the observation in that row matches that category.\nThat sounds pretty tedious, especially if you have a lot of categories…\nLuckily, we have shortcuts in both pandas and sklearn!"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-in-pandas",
    "href": "slides/06-preprocessing.html#dummifying-in-pandas",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying in Pandas",
    "text": "Dummifying in Pandas\n\n\npd.get_dummies(df[[\"Bldg Type\"]])\n\n      Bldg Type_1Fam  Bldg Type_2fmCon  ...  Bldg Type_Twnhs  Bldg Type_TwnhsE\n0               True             False  ...            False             False\n1               True             False  ...            False             False\n2               True             False  ...            False             False\n3               True             False  ...            False             False\n4               True             False  ...            False             False\n...              ...               ...  ...              ...               ...\n2925            True             False  ...            False             False\n2926            True             False  ...            False             False\n2927            True             False  ...            False             False\n2928            True             False  ...            False             False\n2929            True             False  ...            False             False\n\n[2930 rows x 5 columns]"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-in-pandas-1",
    "href": "slides/06-preprocessing.html#dummifying-in-pandas-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying in Pandas",
    "text": "Dummifying in Pandas\n\n\n\n      Bldg Type_1Fam  Bldg Type_2fmCon  ...  Bldg Type_Twnhs  Bldg Type_TwnhsE\n0               True             False  ...            False             False\n1               True             False  ...            False             False\n2               True             False  ...            False             False\n3               True             False  ...            False             False\n4               True             False  ...            False             False\n...              ...               ...  ...              ...               ...\n2925            True             False  ...            False             False\n2926            True             False  ...            False             False\n2927            True             False  ...            False             False\n2928            True             False  ...            False             False\n2929            True             False  ...            False             False\n\n[2930 rows x 5 columns]\n\n\n\n\nSome things to notice here…\n\n\n\n\nWhat is the naming convention for the new columns?\nDoes this change the original dataframe df? If not, what would you need to do to add this information back in?\nWhat happens if you put the whole dataframe into the get_dummies function? What problems might arise from this?"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-in-sklearn",
    "href": "slides/06-preprocessing.html#dummifying-in-sklearn",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying in sklearn",
    "text": "Dummifying in sklearn\nSpecify\n\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder()\n\n\n\nFit\n\n\n\nencoder.fit(df[[\"Bldg Type\"]])\n\n\nOneHotEncoder()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.OneHotEncoder?Documentation for OneHotEncoderiFittedOneHotEncoder() \n\n\n\n\n\nTransform\n\n\ndf_bldg = encoder.transform(df[[\"Bldg Type\"]])\ndf_bldg\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 2930 stored elements and shape (2930, 5)&gt;"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-in-sklearn-1",
    "href": "slides/06-preprocessing.html#dummifying-in-sklearn-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying in sklearn",
    "text": "Dummifying in sklearn\n\n\n\n\ndf_bldg.todense()\n\n\n\n\n\n\n\n\nmatrix([[1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        ...,\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0.]], shape=(2930, 5))\n\n\n\n\n\nThings to notice:\n\n\n\nWhat object type was the result?\nDoes this change the original dataframe df? If not, what would you need to do to add this information back in?\nWhat pros and cons do you see for the pandas approach vs the sklearn approach?"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummifying-in-sklearn-2",
    "href": "slides/06-preprocessing.html#dummifying-in-sklearn-2",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummifying in sklearn",
    "text": "Dummifying in sklearn\nThings to notice:\n\n\nWhat object type was the result?\nDoes this change the original dataframe df? If not, what would you need to do to add this information back in?\nWhat happens if you fit the whole dataframe with the OneHotEncoder? What problems might arise from this?\nWhat pros and cons do you see for the pandas approach vs the sklearn approach?"
  },
  {
    "objectID": "slides/06-preprocessing.html#preprocessing",
    "href": "slides/06-preprocessing.html#preprocessing",
    "title": "Dummy Variables and Column Transformers",
    "section": "Preprocessing",
    "text": "Preprocessing\n\nSo far, we have now seen two preprocessing steps that might need to happen to do an analysis of distances:\n\nScaling the quantitative variables\nDummifying the categorical variables\n\n\n\n\nPreprocessing steps are things you do only to make the following analysis/visualization better.\n\nThis is not the same as data cleaning, where you make changes to fix the data (e.g., changing data types).\nThis is not the same as data wrangling, where you change the structure of the data (e.g., adding or deleting rows or columns)."
  },
  {
    "objectID": "slides/06-preprocessing.html#quick-quiz",
    "href": "slides/06-preprocessing.html#quick-quiz",
    "title": "Dummy Variables and Column Transformers",
    "section": "Quick quiz",
    "text": "Quick quiz\nIdentify the following as cleaning, wrangling, or preprocessing:\n\nRemoving the $ symbol from a column and converting it to numeric.\nNarrowing your data down to only first class Titanic passengers, because you are not studying the others.\nConverting a Zip Code variable from numeric to categorical using .astype().\nCreating a new column called n_investment that counts the number of people who invested in a project.\nLog-transforming a column because it is very skewed."
  },
  {
    "objectID": "slides/06-preprocessing.html#preprocessing-in-sklearn",
    "href": "slides/06-preprocessing.html#preprocessing-in-sklearn",
    "title": "Dummy Variables and Column Transformers",
    "section": "Preprocessing in sklearn",
    "text": "Preprocessing in sklearn\n\n\nUnlike cleaning and wrangling, the preprocessing steps are “temporary” changes to the dataframe.\n\n\n\n\n\nIt would be nice if we could trigger these changes as part of our analysis, instead of doing them “by hand”.\n\nThis is why the specify - fit - transform process is useful!\nWe will first specify all our preprocessing steps.\nThen we will fit the whole preprocess\nThen we will save the transform step for only when we need it."
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-1",
    "href": "slides/06-preprocessing.html#column-transformers-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers",
    "text": "Column Transformers\nTry the following:\n\nWhat happens if you change remainder = \"passthrough\" to remainder = \"drop\"?\nWhat happens if you add the argument sparse_output=False to the OneHotEncoder() function?\nWhat happens if you add this line before the transform step: (keep the sparse_output=False when you try this)\n\npreproc.set_output(transform = \"pandas\")\n\nLook at the preproc object. What does it show you?"
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-2",
    "href": "slides/06-preprocessing.html#column-transformers-2",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers",
    "text": "Column Transformers\nTry the following:\n\nWhat happens if you change remainder = \"passthrough\" to remainder = \"drop\"?\nWhat happens if you add the argument sparse_output=False to the OneHotEncoder() function?\nWhat happens if you add this line before the transform step: (keep the sparse_output=False when you try this)\n\npreproc.set_output(transform = \"pandas\")\n\nLook at the preproc object. What does it show you?"
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-3",
    "href": "slides/06-preprocessing.html#column-transformers-3",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers",
    "text": "Column Transformers\nTry the following:\n\nWhat happens if you change remainder = \"passthrough\" to remainder = \"drop\"?\nWhat happens if you add the argument sparse_output=False to the OneHotEncoder() function?\nWhat happens if you add this line before the transform step: (keep the sparse_output=False when you try this)\n\npreproc.set_output(transform = \"pandas\")\n\nLook at the preproc object. What does it show you?"
  },
  {
    "objectID": "slides/06-preprocessing.html#multiple-preprocessing-steps",
    "href": "slides/06-preprocessing.html#multiple-preprocessing-steps",
    "title": "Dummy Variables and Column Transformers",
    "section": "Multiple Preprocessing Steps",
    "text": "Multiple Preprocessing Steps\nWhy are column transformers so useful? We can do multiple preprocessing steps at once!\n\n\nfrom sklearn.preprocessing import StandardScaler\n\npreproc = make_column_transformer(\n        (StandardScaler(), [\"Gr Liv Area\"]),\n        (OneHotEncoder(sparse_output = False), [\"Bldg Type\", \"Neighborhood\"]),\n        remainder = \"passthrough\")"
  },
  {
    "objectID": "slides/06-preprocessing.html#finding-all-variables",
    "href": "slides/06-preprocessing.html#finding-all-variables",
    "title": "Dummy Variables and Column Transformers",
    "section": "Finding all variables",
    "text": "Finding all variables\nWhat if we just want to say “Please dummify all categorical variables”?\nUse a selector instead of exact column names.\n\nfrom sklearn.compose import make_column_selector\n\npreproc = make_column_transformer(\n    (StandardScaler(),  make_column_selector(dtype_include=np.number)),\n    (OneHotEncoder(sparse_output=False), make_column_selector(dtype_include=object)),\n    remainder=\"passthrough\")\n    \npreproc.fit(df[features])\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt;)]) standardscaler&lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt; StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder&lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt; OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder[] passthroughpassthrough \n\npreproc.set_output(transform = \"pandas\")\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt;)]) standardscaler&lt;sklearn.compose._column_transformer.make_column_selector object at 0x148ce9be0&gt; StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder&lt;sklearn.compose._column_transformer.make_column_selector object at 0x148c87110&gt; OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder[] passthroughpassthrough \n\ndf_transformed = preproc.transform(df[features])\ndf_transformed\n\n      standardscaler__Gr Liv Area  ...  onehotencoder__Neighborhood_Veenker\n0                        0.309265  ...                                  0.0\n1                       -1.194427  ...                                  0.0\n2                       -0.337718  ...                                  0.0\n3                        1.207523  ...                                  0.0\n4                        0.255844  ...                                  0.0\n...                           ...  ...                                  ...\n2925                    -0.982723  ...                                  0.0\n2926                    -1.182556  ...                                  0.0\n2927                    -1.048015  ...                                  0.0\n2928                    -0.219006  ...                                  0.0\n2929                     0.989884  ...                                  0.0\n\n[2930 rows x 37 columns]"
  },
  {
    "objectID": "slides/06-preprocessing.html#think-about-it",
    "href": "slides/06-preprocessing.html#think-about-it",
    "title": "Dummy Variables and Column Transformers",
    "section": "Think about it",
    "text": "Think about it\n\nWhat are the advantages of using a selector?\nWhat are the possible disadvantages of using a selector?\nDoes the order matter when using selectors? Try switching the steps and see what happens!"
  },
  {
    "objectID": "slides/06-preprocessing.html#takeaways-1",
    "href": "slides/06-preprocessing.html#takeaways-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Takeaways",
    "text": "Takeaways\n\nWe dummify or one-hot-encode categorical variables to make them numbers.\nWe can do this with pd.get_dummies() or with OneHotEncoder() from sklearn.\nColumn Transformers let us apply multiple preprocessing steps at the same time.\n\nThink about which variables you want to apply the steps to\nThink about options for the steps, like sparseness\nThink about passthrough in your transformer"
  },
  {
    "objectID": "slides/06-preprocessing.html#dummy-variables",
    "href": "slides/06-preprocessing.html#dummy-variables",
    "title": "Dummy Variables and Column Transformers",
    "section": "Dummy Variables",
    "text": "Dummy Variables\n\nWhen we transform a variable into binary (True / False), we call this variable a dummy variable or we say the variable has been one-hot-encoded.\n\n\nRemember that that computers interpret logical values (True / False) the same as 1 / 0:\n\ndf[\"is_single_fam\"] = df[\"is_single_fam\"].astype(\"int\")\ndf[\"is_single_fam\"].value_counts()\n\nis_single_fam\n1    2425\n0     505\nName: count, dtype: int64"
  },
  {
    "objectID": "slides/06-preprocessing.html#calculating-distances",
    "href": "slides/06-preprocessing.html#calculating-distances",
    "title": "Dummy Variables and Column Transformers",
    "section": "Calculating Distances",
    "text": "Calculating Distances\n\n\ndists = pairwise_distances(df_scaled[[1707]], df_scaled)\nbest = (\n  dists\n  .argsort()\n  .flatten()\n  [1:10]\n  )\ndf_orig.iloc[best]\n\n      Gr Liv Area  Bedroom AbvGr  is_single_fam\n160          2978              5              1\n909          3082              5              1\n1288         2792              5              1\n2350         2784              5              1\n253          3222              5              1\n585          2640              5              1\n2027         2526              5              1\n2330         3390              5              1\n2501         2520              5              1"
  },
  {
    "objectID": "slides/06-preprocessing.html#lecture-3.2-quiz",
    "href": "slides/06-preprocessing.html#lecture-3.2-quiz",
    "title": "Dummy Variables and Column Transformers",
    "section": "Lecture 3.2 Quiz",
    "text": "Lecture 3.2 Quiz\nIdentify the following as cleaning, wrangling, or preprocessing:\n\n\nRemoving the $ symbol from a column and converting it to numeric.\nNarrowing your data down to only first class Titanic passengers, because you are not studying the others.\nConverting a Zip Code variable from numeric to categorical using .astype().\nCreating a new column called n_investment that counts the number of people who invested in a project.\nLog-transforming a column because it is very skewed."
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-specify",
    "href": "slides/06-preprocessing.html#column-transformers-specify",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers – Specify",
    "text": "Column Transformers – Specify\n\nfrom sklearn.compose import make_column_transformer\n\n\n\n\npreproc = make_column_transformer(\n  (OneHotEncoder(), [\"Bldg Type\", \"Neighborhood\"]),\n    remainder = \"passthrough\")"
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-fit-transform",
    "href": "slides/06-preprocessing.html#column-transformers-fit-transform",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers – Fit & Transform",
    "text": "Column Transformers – Fit & Transform\nFit\n\n\n\npreproc.fit(df[features])\n\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('onehotencoder', OneHotEncoder(),\n                                 ['Bldg Type', 'Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('onehotencoder', OneHotEncoder(),\n                                 ['Bldg Type', 'Neighborhood'])]) onehotencoder['Bldg Type', 'Neighborhood'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder() remainder['Gr Liv Area', 'Bedroom AbvGr', 'Full Bath', 'Half Bath'] passthroughpassthrough \n\n\n\n\nTransform\n\n\npreproc.transform(df[features])\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 15717 stored elements and shape (2930, 37)&gt;\n\n\n\nColumn Transformers\nThings to notice…\n\nWhat submodule did we import make_column_transformer from?\nWhat are the two arguments to the make_column_transformer function? What object structures are they?\nWhat happens if you fit and transform on the whole dataset, not just df[features]? Why might this be useful?\n\n\n\nColumn Transformers\nTry the following:\n\nWhat happens if you change remainder = \"passthrough\" to remainder = \"drop\"?\nWhat happens if you add the argument sparse_output=False to the OneHotEncoder() function?\nWhat happens if you add this line before the transform step: (keep the sparse_output=False when you try this)\n\npreproc.set_output(transform = \"pandas\")\n\nLook at the preproc object. What does it show you?\n\n\n\nMultiple preprocessing steps\nWhy are column transformers so useful?\nWell, now we can do multiple preprocessing steps at once!\n\nfrom sklearn.preprocessing import StandardScaler\n\npreproc = make_column_transformer(\n        (StandardScaler(), [\"Gr Liv Area\"]),\n        (OneHotEncoder(sparse_output=False), [\"Bldg Type\",\n                                          \"Neighborhood\"]),\n    remainder=\"passthrough\")\n    \npreproc.fit(df[features])\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])]) standardscaler['Gr Liv Area'] StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['Bldg Type', 'Neighborhood'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder['Bedroom AbvGr', 'Full Bath', 'Half Bath'] passthroughpassthrough \n\npreproc.set_output(transform = \"pandas\")\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])]) standardscaler['Gr Liv Area'] StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['Bldg Type', 'Neighborhood'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder['Bedroom AbvGr', 'Full Bath', 'Half Bath'] passthroughpassthrough \n\ndf_transformed = preproc.transform(df[features])\ndf_transformed\n\n      standardscaler__Gr Liv Area  ...  remainder__Half Bath\n0                        0.309265  ...                     0\n1                       -1.194427  ...                     0\n2                       -0.337718  ...                     1\n3                        1.207523  ...                     1\n4                        0.255844  ...                     1\n...                           ...  ...                   ...\n2925                    -0.982723  ...                     0\n2926                    -1.182556  ...                     0\n2927                    -1.048015  ...                     0\n2928                    -0.219006  ...                     0\n2929                     0.989884  ...                     1\n\n[2930 rows x 37 columns]\n\n\n\n\nFinding all variables\nWhat if we just want to say “Please dummify all categorical variables?”\nUse a selector instead of exact column names.\n\nfrom sklearn.compose import make_column_selector\n\npreproc = make_column_transformer(\n    (StandardScaler(),  make_column_selector(dtype_include=np.number)),\n    (OneHotEncoder(sparse_output=False), make_column_selector(dtype_include=object)),\n    remainder=\"passthrough\")\n    \npreproc.fit(df[features])\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt;)]) standardscaler&lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt; StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder&lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt; OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder[] passthroughpassthrough \n\npreproc.set_output(transform = \"pandas\")\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt;)]) standardscaler&lt;sklearn.compose._column_transformer.make_column_selector object at 0x1107c1be0&gt; StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder&lt;sklearn.compose._column_transformer.make_column_selector object at 0x11075ae90&gt; OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder[] passthroughpassthrough \n\ndf_transformed = preproc.transform(df[features])\ndf_transformed\n\n      standardscaler__Gr Liv Area  ...  onehotencoder__Neighborhood_Veenker\n0                        0.309265  ...                                  0.0\n1                       -1.194427  ...                                  0.0\n2                       -0.337718  ...                                  0.0\n3                        1.207523  ...                                  0.0\n4                        0.255844  ...                                  0.0\n...                           ...  ...                                  ...\n2925                    -0.982723  ...                                  0.0\n2926                    -1.182556  ...                                  0.0\n2927                    -1.048015  ...                                  0.0\n2928                    -0.219006  ...                                  0.0\n2929                     0.989884  ...                                  0.0\n\n[2930 rows x 37 columns]\n\n\n\n\nThink about it\n\nWhat are the advantages of using a selector?\nWhat are the possible disadvantages of using a selector?\nDoes the order matter when using selectors? Try switching the steps and see what happens!\n\n\n\nTakeaways\n\n\n\nTakeaways\n\nWe dummify or one-hot-encode categorical variables to make them numbers.\nWe can do this with pd.get_dummies() or with OneHotEncoder()\nColumn Transformers let us apply multiple preprocessing steps all together.\n\nThink about which variables you want to apply the steps to\nThink about options for the steps, like sparseness\nThink about passthrough in your transformer"
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-fit",
    "href": "slides/06-preprocessing.html#column-transformers-fit",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers – Fit",
    "text": "Column Transformers – Fit\n\npreproc.fit(df[features])\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('onehotencoder', OneHotEncoder(),\n                                 ['Bldg Type', 'Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('onehotencoder', OneHotEncoder(),\n                                 ['Bldg Type', 'Neighborhood'])]) onehotencoder['Bldg Type', 'Neighborhood'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder() remainder['Gr Liv Area', 'Bedroom AbvGr', 'Full Bath', 'Half Bath'] passthroughpassthrough"
  },
  {
    "objectID": "slides/06-preprocessing.html#column-transformers-transform",
    "href": "slides/06-preprocessing.html#column-transformers-transform",
    "title": "Dummy Variables and Column Transformers",
    "section": "Column Transformers – Transform",
    "text": "Column Transformers – Transform\n\npreproc.transform(df[features])\n\n&lt;Compressed Sparse Row sparse matrix of dtype 'float64'\n    with 15717 stored elements and shape (2930, 37)&gt;"
  },
  {
    "objectID": "slides/06-preprocessing.html#things-to-notice",
    "href": "slides/06-preprocessing.html#things-to-notice",
    "title": "Dummy Variables and Column Transformers",
    "section": "Things to notice…",
    "text": "Things to notice…\n\nWhat submodule did we import make_column_transformer from?\nWhat are the two arguments to the make_column_transformer() function? What object structures are they?\nWhat happens if you fit and transform on the whole dataset, not just df[features]? Why might this be useful?"
  },
  {
    "objectID": "slides/06-preprocessing.html#lecture-4.1-quiz",
    "href": "slides/06-preprocessing.html#lecture-4.1-quiz",
    "title": "Dummy Variables and Column Transformers",
    "section": "Lecture 4.1 Quiz",
    "text": "Lecture 4.1 Quiz\nIdentify the following as cleaning, wrangling, or preprocessing:\n\n\nRemoving the $ symbol from a column and converting it to numeric.\nNarrowing your data down to only first class Titanic passengers, because you are not studying the others.\nConverting a Zip Code variable from numeric to categorical using .astype().\nCreating a new column called n_investment that counts the number of people who invested in a project.\nLog-transforming a column because it is very skewed."
  },
  {
    "objectID": "slides/06-preprocessing.html#lecture-activity-4.2",
    "href": "slides/06-preprocessing.html#lecture-activity-4.2",
    "title": "Dummy Variables and Column Transformers",
    "section": "Lecture Activity 4.2",
    "text": "Lecture Activity 4.2\nTry the following:\n\nWhat happens if you change remainder = \"passthrough\" to remainder = \"drop\"?\nWhat happens if you add the argument sparse_output = False to the OneHotEncoder() function?\nWhat happens if you add this line before the transform step: preproc.set_output(transform = \"pandas\") (keep the sparse_output = False when you try this)"
  },
  {
    "objectID": "slides/06-preprocessing.html#fit",
    "href": "slides/06-preprocessing.html#fit",
    "title": "Dummy Variables and Column Transformers",
    "section": "Fit!",
    "text": "Fit!\n\n(\n  preproc\n  .fit(df[features])\n  .set_output(transform = \"pandas\")\n)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 ['Gr Liv Area']),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 ['Bldg Type', 'Neighborhood'])]) standardscaler['Gr Liv Area'] StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder['Bldg Type', 'Neighborhood'] OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder['Bedroom AbvGr', 'Full Bath', 'Half Bath'] passthroughpassthrough"
  },
  {
    "objectID": "slides/06-preprocessing.html#transform",
    "href": "slides/06-preprocessing.html#transform",
    "title": "Dummy Variables and Column Transformers",
    "section": "Transform!",
    "text": "Transform!\n\n\ndf_transformed = preproc.transform(df[features])\ndf_transformed\n\n      standardscaler__Gr Liv Area  ...  remainder__Half Bath\n0                        0.309265  ...                     0\n1                       -1.194427  ...                     0\n2                       -0.337718  ...                     1\n3                        1.207523  ...                     1\n4                        0.255844  ...                     1\n...                           ...  ...                   ...\n2925                    -0.982723  ...                     0\n2926                    -1.182556  ...                     0\n2927                    -1.048015  ...                     0\n2928                    -0.219006  ...                     0\n2929                     0.989884  ...                     1\n\n[2930 rows x 37 columns]"
  },
  {
    "objectID": "slides/06-preprocessing.html#finding-all-categorical-variables",
    "href": "slides/06-preprocessing.html#finding-all-categorical-variables",
    "title": "Dummy Variables and Column Transformers",
    "section": "Finding All Categorical Variables",
    "text": "Finding All Categorical Variables\nWhat if we want to tell sklearn, “Please dummify every categorical variable.”? Use a selector instead of exact column names!\n\n\n\nfrom sklearn.compose import make_column_selector\n\npreproc = make_column_transformer(\n    (StandardScaler(),  \n     make_column_selector(dtype_include = np.number)\n     ),\n    (OneHotEncoder(sparse_output = False), \n     make_column_selector(dtype_include = object)\n     ),\n    remainder = \"passthrough\")"
  },
  {
    "objectID": "slides/06-preprocessing.html#fit-1",
    "href": "slides/06-preprocessing.html#fit-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Fit!",
    "text": "Fit!\n\n(\n  preproc\n  .fit(df[features])\n  .set_output(transform = \"pandas\")\n)\n\nColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x112529be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1124c6fd0&gt;)])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriFittedColumnTransformer(remainder='passthrough',\n                  transformers=[('standardscaler', StandardScaler(),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x112529be0&gt;),\n                                ('onehotencoder',\n                                 OneHotEncoder(sparse_output=False),\n                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x1124c6fd0&gt;)]) standardscaler&lt;sklearn.compose._column_transformer.make_column_selector object at 0x112529be0&gt; StandardScaler?Documentation for StandardScalerStandardScaler() onehotencoder&lt;sklearn.compose._column_transformer.make_column_selector object at 0x1124c6fd0&gt; OneHotEncoder?Documentation for OneHotEncoderOneHotEncoder(sparse_output=False) remainder[] passthroughpassthrough"
  },
  {
    "objectID": "slides/06-preprocessing.html#transform-1",
    "href": "slides/06-preprocessing.html#transform-1",
    "title": "Dummy Variables and Column Transformers",
    "section": "Transform!",
    "text": "Transform!\n\n\ndf_transformed = preproc.transform(df[features])\ndf_transformed\n\n      standardscaler__Gr Liv Area  ...  onehotencoder__Neighborhood_Veenker\n0                        0.309265  ...                                  0.0\n1                       -1.194427  ...                                  0.0\n2                       -0.337718  ...                                  0.0\n3                        1.207523  ...                                  0.0\n4                        0.255844  ...                                  0.0\n...                           ...  ...                                  ...\n2925                    -0.982723  ...                                  0.0\n2926                    -1.182556  ...                                  0.0\n2927                    -1.048015  ...                                  0.0\n2928                    -0.219006  ...                                  0.0\n2929                     0.989884  ...                                  0.0\n\n[2930 rows x 37 columns]"
  },
  {
    "objectID": "slides/02-conditional-distributions.html",
    "href": "slides/02-conditional-distributions.html",
    "title": "Visualizing and Comparing Categorical Variables",
    "section": "",
    "text": "df = pd.read_csv(\"https://datasci112.stanford.edu/data/titanic.csv\")\n\n\ndf[\"pclass\"] = df[\"pclass\"].astype(\"category\")\ndf[\"survived\"] = df[\"survived\"].astype(\"category\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nname\npclass\nsurvived\nsex\nage\nsibsp\nparch\nticket\nfare\ncabin\nembarked\nboat\nbody\nhome.dest\n\n\n\n\nAllen, Miss. Elisabeth Walton\n1\n1\nfemale\n29.0000\n0\n0\n24160\n211.3375\nB5\nS\n2\nNaN\nSt Louis, MO\n\n\nAllison, Master. Hudson Trevor\n1\n1\nmale\n0.9167\n1\n2\n113781\n151.5500\nC22 C26\nS\n11\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Miss. Helen Loraine\n1\n0\nfemale\n2.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Mr. Hudson Joshua Creighton\n1\n0\nmale\n30.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\n135\nMontreal, PQ / Chesterville, ON\n\n\nAllison, Mrs. Hudson J C (Bessie Waldo Daniels)\n1\n0\nfemale\n25.0000\n1\n2\n113781\n151.5500\nC22 C26\nS\nNA\nNaN\nMontreal, PQ / Chesterville, ON\n\n\nAnderson, Mr. Harry\n1\n1\nmale\n48.0000\n0\n0\n19952\n26.5500\nE12\nS\n3\nNaN\nNew York, NY\n\n\n\n\n\n\n\n\n\n\n\n\ndf.iloc[5,]\n\nname         Anderson, Mr. Harry\npclass                         1\nsurvived                       1\nsex                         male\nage                         48.0\nsibsp                          0\nparch                          0\nticket                     19952\nfare                       26.55\ncabin                        E12\nembarked                       S\nboat                           3\nbody                         NaN\nhome.dest           New York, NY\nName: 5, dtype: object\n\n\n\n\ndf[\"name\"].head()\n\n0                      Allen, Miss. Elisabeth Walton\n1                     Allison, Master. Hudson Trevor\n2                       Allison, Miss. Helen Loraine\n3               Allison, Mr. Hudson Joshua Creighton\n4    Allison, Mrs. Hudson J C (Bessie Waldo Daniels)\nName: name, dtype: object\n\n\n\n\n\n\n\n\n\ndf.describe()\n\n               age        sibsp        parch         fare        body\ncount  1046.000000  1309.000000  1309.000000  1308.000000  121.000000\nmean     29.881135     0.498854     0.385027    33.295479  160.809917\nstd      14.413500     1.041658     0.865560    51.758668   97.696922\nmin       0.166700     0.000000     0.000000     0.000000    1.000000\n25%      21.000000     0.000000     0.000000     7.895800   72.000000\n50%      28.000000     0.000000     0.000000    14.454200  155.000000\n75%      39.000000     1.000000     0.000000    31.275000  256.000000\nmax      80.000000     8.000000     9.000000   512.329200  328.000000\n\n\n\n\n\n\nThe list of percents for each category is called the distribution of the variable.\n\ndf[\"pclass\"].value_counts()\n\npclass\n3    709\n1    323\n2    277\nName: count, dtype: int64\n\ndf[\"pclass\"].value_counts(normalize = True)\n\npclass\n3    0.541635\n1    0.246753\n2    0.211612\nName: proportion, dtype: float64",
    "crumbs": [
      "Lecture Slides",
      "Week 1, Part 2 - Visualizing and Comparing Categorical Variables"
    ]
  }
]